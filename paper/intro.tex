\section{Introduction}

The State-Machine Replication technique (abbreviated SMR) allows
building reliable services on top of unreliable hardware. The basic idea is to 
replicate a service over several servers, each executing the same
sequence of (deterministic) commands. 
Making SMR algorithms efficient has been a long-standing
challenge and a multitude of algorithms have been proposed. Examples
include Paxos \cite{lamport2001paxos}, Fast Paxos \cite{Lamport06FastPaxos}, Disk Paxos
\cite{GafniLamport03DiskPaxos}, Chain Replication
\cite{RenesseSchneider04ChainReplicationSupportingHighThroughputAvailability},
Ring Paxos
\cite{MarandiETAL10RingPaxosHighthroughputAtomicBroadcastProtocol},
Egalitarian Paxos
\cite{MoraruAndersenKaminsky13ThereIsMoreConsensusEgalitarianParliaments},
Multi-Coordinated Paxos
\cite{CamargosSchmidtPedone07MulticoordinatedPaxos}, Cheap Paxos
\cite{LamportMassa04CheapPaxos}, Vertical Paxos
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication},
Paxos-MIC
\cite{HurfinMoiseNarzul11AdaptiveFastPaxosMakingQuickEverlasting},
Mencius
\cite{MaoJunqueiraMarzullo08MenciusBuildingEfficientReplicatedStateMachine},
Fast Mencius \cite{WeiETAL13FastMenciusMenciusLowCommitLatency}, the Chandra-Toueg \cite{ChandraToueg96UnreliableFailureDetectorsReliableDistributedSystems}, the Ben-Or algorithm \cite{BenOr83AnotherAdvantageFreeChoiceCompletelyAsynchronous}, and Raft \cite{OngaroOusterhout14SearchUnderstandableConsensusAlgorithm}.

With the wide use of cloud computing, improvements in the performance and efficiency of SMR algorithms have the potential to impact most online services: advanced SMR algorithms can be implemented by cloud computing service providers and benefit all their customer's applications.

However, devising new SMR algorithms, optimized with particular situations or metrics in mind, is hard: today, more than two decades after the first SMR algorithms \cite{Lamport98ParttimeParliament,BirmanJoseph87ReliableCommunicationPresenceFailures,OkiLiskov88ViewstampedReplicationGeneralPrimaryCopy,DworkLynchStockmeyer84ConsensusPresencePartialSynchronyPreliminaryVersion} were published, devising new SMR algorithms is still hard enough to justify a publication in a top conference \cite{MoraruAndersenKaminsky13ThereIsMoreConsensusEgalitarianParliaments,OngaroOusterhout14SearchUnderstandableConsensusAlgorithm}.

The problem is that it is very hard to reuse existing algorithms and ideas because SMR algorithms are not modular. When devising a new algorithm, all the careful analysis, tests, and proofs have to be done again from scratch.

We propose a framework to make existing SMR algorithms modular and add new optimizations incrementally, without modification to the existing. 
An algorithm in our framework is composed of independent modules that can run, abort their execution, and pass the baton to any other module.

Crucially, when adding a new module to an existing algorithm, all the performance analysis, tests, and proofs of the existing modules remain valid and only the new SMR module needs to be analyzed: Our composition theorem guarantees that the composition of any number of correct modules is a correct SMR algorithm, thus one can combine different SMR algorithms, optimized for different situations and metrics, without any changes and with guaranteed correctness.
Our framework therefore enables incremental development of SMR algorithms, where each new development can build on the previous ones instead of starting again from scratch.

Moreover, our framework enables a clear separation of concerns  which simplifies the designing individual modules.
A composite SMR algorithm built with our framework works by running the SMR module deemed the most appropriate at any given time, dynamically changing SMR module when needed. Therefore a composable SMR algorithm is not required to make progress in all situations: if it does not, the system can switch to another SMR algorithm.
Thus algorithms designers who want to create a new SMR algorithm, optimized for particular conditions, can focus only on the particular conditions of interest, knowing that the other existing modules will handle the other cases. 

The key novelty of our framework lies in its practical applicability, allowing the execution of commutative commands without synchronization and reducing the replication overhead from $2*k+1$ replicas to $k+1$ replicas, to tolerate $k$ replica crashes, using a reliable reconfiguration master.

Allowing the execution of commuting commands to proceed without synchronization is an important practical optimization, as commands may often commute in practice, for example when operating on disjoint parts of a data structure. 
To enable the synchronization-free execution of commuting commands, we have based our framework on Generalized Consensus \cite{Lamport05GeneralizeConsensus}. Traditional SMR implementations are implemented by having all the replicas execute the same sequence of commands, using a separate instance of a consensus algorithm to agree on the command to execute at each index of the command sequence. Using separate instances of a consensus algorithm for each index in the sequence of commands
makes it hard to optimize the execution of commuting command because commutativity is not a property of a single command.
Instead of restricting agreement on a single value, as in the consensus problem, in the  Generalized Consensus problem the set of replica servers must agree on the state of a growing data structure called a command-structure set. A command-structure set is a data structure with an append operation such that the order in which two commuting commands are appended does not change the resulting state. Thanks to this property, two replicas executing commuting commands in a different order will
not end up in a different state and can continue executing without further synchronization. This property can be leveraged to reduce the latency of processing one command to two message delays instead of three in message passing systems. As we will show, it also enables the processing of read-only commands in two message delays, although read-only commands do not commute with write commands.

In practice, a SMR algorithm must support fast reconfiguration to replace faulty components, without which the long-term stability of a system is inevitably compromised. Our framework clearly separates the execution of commands from the reconfiguration decisions (including changing SMR module), allowing the use of an external reconfiguration master. This enables tolerating $k$ failures with $k+1$ replicas, an important improvement over the traditional $2k+1$ needed replicas.

To demonstrate the practical applicability of our framework we provide composable versions of the generalized variations of popular algorithms like the classic Paxos, Fast Paxos, and multi-coordinated Paxos. We have checked the composability of these algorithms with the TLC model-checker and we provide all the specifications needed to replicate these experiments.

Our framework is also fully formalized and its composition theorem proved in the foundational interactive theorem prover Isabelle/HOL, certifying the correctness of the composition theorem at the deepest level.

At the heart of our framework lies a simple abstraction of the familiar notion of rounds (also called epochs, ballots, or views in the literature) used in most SMR algorithms. To illustrate our approach, let us consider Fast Paxos, one of the first examples of SMR algorithm which can change mode dynamically.
Fast Paxos is a round-based SMR algorithm that has two types of rounds: fast rounds and normal rounds. Fast rounds process requests faster than normal rounds in contention-free executions but fall back to a slower scheme under contention. Normal rounds are the same as in the classic Paxos. Any process can initiate a round change at any point during execution: this allows switching between fast and normal rounds as well as, similarly to classic Paxos, changing the leader from one normal round to
another. Each kind of round maintains different invariants relating the state of each process and the values that might have been chosen in the previous rounds, thus a normal round must know which past rounds are fast or normal rounds in order to take over the execution safely. When adding more kinds of rounds such an approach will quickly become unmanageable, as each type of rounds must have one case for each possible other kind of round, making $n^2$ cases to consider in total.

Our notion of Composable Generalized Consensus defines a common interface and a common correctness property for a round, abstracting over the particular round implementations and making all rounds compatible with each other. 
Moreover, our interface for rounds enable a crucial optimization seen in practical systems: introducing an external reconfiguration master which manages the addition of new replicas and the removal of failed ones. Interestingly, as explained in \cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication}, in a real system it is often possible to implement a reliable reconfiguration master which allows to tolerate $f$ faults with $f+1$ replicas instead of the traditional $2f+1$ replicas.
The reconfiguration master can also make the choice of the new type of round to execute, providing the system's reconfiguration policy. 
