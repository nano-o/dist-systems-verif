\section{Introduction}

The State-Machine Replication technique (abbreviated SMR) allows
building reliable services on top of unreliable hardware. The basic idea is to 
replicate a service over several servers, each executing the same
sequence of (deterministic) commands. 
Making SMR algorithms efficient has been a long-standing
challenge and a multitude of algorithms have been proposed. Examples
include Paxos \cite{lamport2001paxos}, Fast Paxos \cite{Lamport06FastPaxos}, Disk Paxos
\cite{GafniLamport03DiskPaxos}, Chain Replication
\cite{RenesseSchneider04ChainReplicationSupportingHighThroughputAvailability},
Ring Paxos
\cite{MarandiETAL10RingPaxosHighthroughputAtomicBroadcastProtocol},
Egalitarian Paxos
\cite{MoraruAndersenKaminsky13ThereIsMoreConsensusEgalitarianParliaments},
Multi-Coordinated Paxos
\cite{CamargosSchmidtPedone07MulticoordinatedPaxos}, Cheap Paxos
\cite{LamportMassa04CheapPaxos}, Vertical Paxos
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication},
Paxos-MIC
\cite{HurfinMoiseNarzul11AdaptiveFastPaxosMakingQuickEverlasting},
Mencius
\cite{MaoJunqueiraMarzullo08MenciusBuildingEfficientReplicatedStateMachine},
Fast Mencius \cite{WeiETAL13FastMenciusMenciusLowCommitLatency}, the Chandra-Toueg \cite{ChandraToueg96UnreliableFailureDetectorsReliableDistributedSystems}, the Ben-Or algorithm \cite{BenOr83AnotherAdvantageFreeChoiceCompletelyAsynchronous}, and Raft \cite{OngaroOusterhout14SearchUnderstandableConsensusAlgorithm}.

With the wide use of cloud computing, improvements in the performance and efficiency of SMR algorithms have the potential to impact most online services: advanced SMR algorithms can be implemented by cloud computing service providers and benefit all their customer's applications.

However, devising new SMR algorithms, optimized with particular situations or metrics in mind, is hard: today, more than two decades after the first SMR algorithms \cite{Lamport98ParttimeParliament,BirmanJoseph87ReliableCommunicationPresenceFailures,OkiLiskov88ViewstampedReplicationGeneralPrimaryCopy,DworkLynchStockmeyer84ConsensusPresencePartialSynchronyPreliminaryVersion} were published, devising new SMR algorithms is still hard enough to justify a publication in a top conference \cite{MoraruAndersenKaminsky13ThereIsMoreConsensusEgalitarianParliaments,OngaroOusterhout14SearchUnderstandableConsensusAlgorithm}.

The problem is that it is very hard to reuse existing algorithms and ideas because SMR algorithms are not modular. When devising a new algorithm, all the careful analysis, tests, and proofs have to be done again from scratch.

We propose a framework to make existing SMR algorithms modular and add new optimizations incrementally, without modification to the existing. 
An algorithm in our framework is composed of independent modules that can run, abort their execution, and pass the baton to any other module.

Crucially, when adding a new module to an existing algorithm, all the performance analysis, tests, and proofs of the existing modules remain valid and only the new SMR module needs to be analyzed: Our composition theorem guarantees that the composition of any number of correct modules is a correct SMR algorithm, thus one can combine different SMR algorithms, optimized for different situations and metrics, without any changes and with guaranteed correctness.
Our framework therefore enables incremental development of SMR algorithms, where each new development can build on the previous ones instead of starting again from scratch.

Moreover, our framework enables a clear separation of concerns  which simplifies the designing individual modules.
A composite SMR algorithm built with our framework works by running the SMR module deemed the most appropriate at any given time, dynamically changing SMR module when needed. Therefore a composable SMR algorithm is not required to make progress in all situations: if it does not, the system can switch to another SMR algorithm.
Thus algorithms designers who want to create a new SMR algorithm, optimized for particular conditions, can focus only on the particular conditions of interest, knowing that the other existing modules will handle the other cases. 

The key novelty of our framework lies in its practical applicability. In practice, a SMR algorithm must support fast reconfiguration to replace faulty components, without which the long-term stability of a system is inevitably compromised. Our framework clearly separates the execution of commands from the reconfiguration decisions (including changing SMR module), allowing the use of an external reconfiguration master. This enables tolerating $k$ failures with $k+1$ replicas, a very
important improvement over the traditional $2k+1$ needed replicas.
Moreover, in practice, commands sent to a SMR algorithm often commute. Our framework is based on Generalized Consensus, a formulation of the State-Machine Replication problem that allows processing commutative commands without synchronization.

TODO: expand on the preceding paragraph.

Our framework is fully formalized and its composition theorem proved in Isabelle/HOL. Moreover, to quickly check concrete modules, we also provide a TLA+ specification of our framework which allows model-checking algorithms with the TLC model-checker. 

TODO: the two abstract specs.

At the heart of our framework lies a simple abstraction of the familiar notion of rounds (also called epochs, ballots, or views in the literature) used in most SMR algorithms. To illustrate our approach, let us consider Fast Paxos, one of the first examples of SMR algorithm which can change mode dynamically.
Fast Paxos is a round-based SMR algorithm that has two types of rounds: fast rounds and normal rounds. Fast rounds process requests faster than normal rounds in contention-free executions but fall back to a slower scheme under contention. Normal rounds are the same as in the classic Paxos. Any process can initiate a round change at any point during execution: this allows switching between fast and normal rounds as well as, similarly to classic Paxos, changing the leader from one normal round to
another. Each kind of round maintains different invariants relating the state of each process and the values that might have been chosen in the previous rounds, thus a normal round must know which past rounds are fast or normal rounds in order to take over the execution safely. When adding more kinds of rounds such an approach will quickly become unmanageable, as each type of rounds must have one case for each possible other kind of round, making $n^2$ cases to consider in total.

Our notion of Composable Generalized Consensus defines a common interface and a common correctness property for a round, abstracting over the particular round implementations and making all rounds compatible with each other. 
Moreover, our interface for rounds enable a crucial optimization seen in practical systems: introducing an external reconfiguration master which manages the addition of new replicas and the removal of failed ones. Interestingly, as explained in \cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication}, in a real system it is often possible to implement a reliable reconfiguration master which allows to tolerate $f$ faults with $f+1$ replicas instead of the traditional $2f+1$ replicas.
The reconfiguration master can also make the choice of the new type of round to execute, providing the system's reconfiguration policy. 
