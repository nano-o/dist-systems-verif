\input{header.tex}
\input{defs.tex}

\addbibresource{mjanaged}

\title{Changing Flights In The Air\\ (Abortable Chain Agreement)}

\author{
  Rachid Guerraoui\\
  \texttt{rachid.guerraoui@epfl.ch}
  \and
  Giuliano Losa\\
  \texttt{giuliano.losa@epfl.ch}
}

\date{}

\begin{document}

\maketitle

\input{abstract3}

\vspace{2cm}

\begin{center}
This paper is a regular submission.

\vspace{1cm}
This paper is a student paper.
\end{center}

\newpage

\input{intro}
\input{roadmap}

\begin{comment}
Abortable Chain Agreement builds on several recent advances in SMR
algorithms: ACA allows acceptors to only eventually reach agreement,
like in Generalized Paxos \cite{Lamport05GeneralizeConsensus},
boosting performance when most commands commute; ACA allows fast
execution of read commands like in Generalized Lattice Agreement
\cite{FalerioETAL12GeneralizedLatticeAgreement}; ACA implementations
can tolerate $f$ faults with only $f+1$ replicas and replace crashed replicas
upon changing round, as in Vertical Paxos  \cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication}.  
\end{comment}

\section{Related Work}
\label{sec:related}

SMR is often implemented using a sequence of instances of Consensus.
There are numerous examples of consensus algorithms in the literature.
However, Abortable Chain Agreement is based on Generalized Consensus. 
In Generalized Consensus \cite{Lamport05GeneralizeConsensus}, the learners of a
SMR algorithm repeatedly learn new values belonging to a \emph{C-struct set}. A
C-struct can be seen as a data structure encoding  sequences of commands modulo
the ordering of commands that commute. The advantage of Generalized
Consensus over Consensus is that
two servers which receive commuting commands in different orders can still reach
agreement on C-structs without further synchronization. 
Our Abortable Chain Agreement can also use C-structs, with the same advantages
as Generalized Consensus. For simplicity, the presentation in this
paper uses the more concrete notion of \emph{command history} (see
\cref{sec:histories}).

Generalized Lattice Agreement \cite{FalerioETAL12GeneralizedLatticeAgreement} allows more efficient implementations of SMR when
commands are partitioned into read-only commands and write-only commands.
Abortable Chain Agreement supports the same optimizations as Generalized Lattice Agreement.
Notably, read-only commands are treated specially so as to optimize their
executions (see \cref{sec:readonly}).

Vertical Paxos algorithms 
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication} are SMR algorithms
whose set of replica servers can be reconfigured without stopping to process new
commands. Crashed servers can therefore be replaced by new servers, ensuring the
long-term availability of a replicated service.
Vertical Paxos algorithms use an external reconfiguration master, itself
implemented as a replicated state machine, which determines the servers that should
be removed from or added to the configuration.
ACA shares some aspects of Vertical Paxos algorithms: the task of the
reconfiguration master is similar to the task of the scheduling policy
component of ACA (see \cref{sec:aca}).
However, in ACA, changing round can be used not only to replace crashed servers
but also to change the algorithm that the servers are running. 
Changing algorithm is not possible in Vertical Paxos.
In both Vertical Paxos and ACA, a reliable reconfiguration master, resp. a
reliable scheduling policy, allows tolerating $f$ crashes with $f+1$ servers.

The Abstract Framework \cite{GuerraouiETAL10Next700BftProtocols} proposes to
build Byzantine Fault-Tolerant algorithms as the succession of abortable rounds
called Abstract instances. Abstract instances must satisfy the Abstract
correctness properties. By construction, the composition of any number of
Abstract instances is a correct SMR implementation. However, the Abstract
Framework uses totally ordered sequence of commands, making difficult the
optimization of the execution of commuting and read-only commands that are
possible with ACA.  Moreover, the Abstract Framework does not identify the
crucial role of the scheduling policy for the long-term resilience of a service.
Abortable Chain Agreement combines the ideas of the Abstract Framework,
Generalized Paxos, Generalized Lattice Agreement, and Vertical Paxos in a
unified abstraction. 

Finally, the Speculative Linearizability framework
\cite{GuerraouiKuncakLosa12SpeculativeLinearizability} was a first
attempt by the authors of the present paper at generalizing the
Abstract Framework and mechanically proving its properties with the
Isabelle/HOL interactive
proofs assistant.  Like the Abstract Framework, the
Speculative Linearizability framework is based on totally ordered
sequences of commands, with the same drawback for the execution of
commuting and read-only commands. Moreover, Abortable Chain Agreement is both
conceptually simpler and subsumes the Speculative Linearizability
property.  Like Speculative Linearizability, Abortable Chain Agreement
and its main property, the composition theorem (\cref{thm:comp}), are
formalized in Isabelle/HOL (see \cref{sec:isaproofs}).

Abortable Chain Agreement is the most complete framework to date for building
adaptive replication algorithms out of heterogeneous rounds, making state of the
art optimization techniques available to algorithm designers, which was not
possible before.

\section{Chain Agreement}
\label{sec:ca}

We consider a set of asynchronous servers communicating by message passing in an
asynchronous network. Servers are not necessarily sequential processes. We
describe a behavior of the system using an infinite sequence of states, where a
state is a function from variable names to values (i.e. a valuation
of variables).  We specify sets of allowed behaviors using an initial predicate,
a next-state relation (using unprimed and primed variables) and a fairness
condition, all in the style of TLA+ \cite{Lamport02SpecifyingSystems}. However,
for succinctness, our specification are rather informal, eluding non-essential
details.

Our specifications all contain by default a state variable $crashed$ and
$Crash\left( x \right)$ transition which is always enabled. A server $x$ faithfully
executes the algorithm that is assigned to it until its identifier is added to
the variable $crashed$ by a $Crash\left( x \right)$ transitions.  When the identifier of a
server is in the set $crashed$, all its actions are disabled.  In an execution,
a server that is never added to the set $crashed$ is said correct.

We consider a computing service exposing a set of commands $C$. The
service has a sequential specification consisting of an initial state
and a deterministic transition relation in which every command
atomically updates the state of the service and produces an output. We
assume that duplicate commands have no effect on the state of the
service and return the same output as their first occurrence.

In a traditional SMR algorithm, the servers can be seen has playing one or
several of three roles: \emph{proposers}, which propose new commands to execute,
\emph{acceptors}, which accept and order commands in a sequence, and
\emph{learners}, which learn about the growing sequence of commands to
execute \cite{lamport2001paxos}. Often, but not necessarily, every replica server plays the
three roles of proposer, acceptor, and learner: clients of the service
send their commands to some replica servers; replica servers submit
the received commands to the SMR protocol in the role of proposers;
replica servers respond to commands by executing the commands learned
in the role of learners; replica servers participate in command
ordering in the role of acceptors.  An SMR algorithm guarantees that
the replicas learn the same sequences of commands, possibly up to the
reordering of commuting commands. Therefore, every learner can respond to client
requests using its last learned sequence of commands, and clients will receive
the same responses as the ones produces by a centralized, non-replicated,
service. 

Chain Agreement precisely specifies the allowed behaviors of the roles of \emph{proposers}
and \emph{learners}, abstracting over the behavior of acceptors. 

\begin{comment}
We suppose that each server can play a number of \emph{roles}.
Chain Agreement specifies the allowed behaviors the roles of \emph{proposers}
and \emph{learners}. Proposers receive commands from the clients of the service
and propose them for execution by the replicated service. Each learner learns about
a growing sequence of commands. Thanks to the sequential specification of the
service, a sequence of commands determines an output for each the included commands. 
In a traditional SMR algorithm, servers can also play the role of
\emph{acceptors}, whose task is to collectively order commands and let the
learners know about the latest sequence of ordered commands.

The point of Chain Agreement is to implement a replicated service by having every learner learn about a growing sequence of commands, which
represent an execution of the sequential specification of the service.
Crucially, at all times, the sequences of commands learned by the
different learners must form a chain in the prefix order on sequences.
Moreover, for every command $c$ proposed by a correct proposer, every
correct learner must eventually learn a sequence containing $c$.  Once
a learner learns about a sequence containing a command $c$, it can
determine the output produced by $c$, using the sequential
specification of the service, and respond to the client that issued
the command $c$.
\end{comment}

To specify Chain Agreement, we need the notion of ordering of sequences and of
maximum sequence.  The prefix order on sequences is denoted by the operator
$\leq$ ($s_1 \leq s_2$ means that $s_1$ is a prefix of $s_2$). 
%Using the operator $\leq$, we define $\geq$, $<$, and $>$ as expected. 
Note that $\leq$ is a partial order on sequences. The maximum over a set of
sequences $S$ is denoted by $Max\left( S \right)$ and $Max\left( \aset{}
\right)$ is the empty sequence.

We specify Chain Agreement using the state variables $crashed$, $proposed$, containing the proposed commands,
and, for every learner $l$,  $learned\left[ l \right]$, a set of
sequences of commands. Initially, $crashed$, $proposed$ and, for every learner $l$,
$learned\left[ l \right]$ are empty sets. 
Remember that any transition involving a server $x$ is always disabled when $x\in crashed$. 

The next-state relation consists of three types of transitions:
$Crash\left( x \right)$ transitions; $Propose\left( l, c
\right)$ transitions, for a learner $l$ and a command $c$, in which
$c$ is inserted in the set $proposed$; $Learn\left( l,cs \right)$
transitions, for a learner $l$ and a sequence of commands $cs$, in
which $cs$ is inserted in $learned\left[ l \right]$. 
A $Learn\left( l, cs \right)$ transition is guarded by the following
conditions:
\begin{compactitem}
    \item[\textbf{Agreement}:] The elements of the set $\aset{learned'\left[ l
      \right] : l \in Learners}$, the learned sequences after the transition,
      form a chain in the partial order $\leq$.
    \item[\textbf{Validity}:] Every learned sequence contains only
        proposed commands.  
    \item[\textbf{Irrevocability}:] The new learned sequence
        $cs$ is a strict extension of $Max\left(learned\left[ l
        \right]\right)$. 
        %\\ $cs > Max\left(learned\left[ l \right]\right)$.
\end{compactitem}
Finally, we add, for every learner $l$, one weak fairness condition
\cite{Lamport02SpecifyingSystems} on the transitions $Learn\left( l,
cs \right)$. The weak fairness conditions ensure that every correct
learner eventually learns about every proposed command.

Thanks to the properties of Chain Agreement, the clients, observing
their input commands and the received responses, see a
\emph{linearizable} execution
\cite{HerlihyWing90LinearizabilityCorrectnessConditionConcurrentObjects}.
Moreover, the service remains available as long as at least one
proposer and one learner are correct.

\section{Abortable Chain Agreement}
\label{sec:aca}

We now consider implementing Chain Agreement as a sequence of \emph{Abortable Chain
Agreement rounds}, where each round makes progress ordering requests or aborts
its execution and passes the baton to the next round in the sequence.
An algorithm composed of a sequence of ACA rounds is called an \emph{ACA
algorithm}.

On top of the traditional roles of proposer, acceptor, and learner, ACA
introduces the new role of \emph{switcher} and a new component, the
\emph{scheduling policy}. In ACA, the assignment of the roles of proposer,
acceptor, learner, and switcher can change in each rounds, allowing for
reconfiguration. 
In normal circumstances, the proposers, acceptors,
and learners of an ACA round work together to implement Chain Agreement.
However, if the environment becomes unfavorable to a running ACA round, the
scheduling policy can instruct the round to abort its execution and pass the
baton, using the switchers, to a new round.

A switcher of an aborting round determines, from the state of the
acceptors, an \emph{abort sequence} that it transfers to one or several
switchers of the new round.  Upon receiving an abort sequence, a switcher of the
new round initializes the acceptors of the new round, which can then
proceed implementing SMR, until the new round itself aborts and the
process is repeated. 
We assume that in the first round, which has no previous round, every 
switchers receives the empty abort sequence.

The scheduling policy determines when to abort an ACA round and which new ACA
round should take over. The scheduling policy must inform the switchers about the
identity of the next round and must guarantee that all switchers receive the
same information.  In this paper we abstract over the scheduling policy, assuming
that a round that aborts passes the baton a nondeterministically chosen new
round. A reliable scheduling-policy component can realistically be implemented
as a replicated state machine running on a large number of servers otherwise
dedicated to other tasks
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication}. We will see
 in \cref{sec:rounds} that, as in Vertical Paxos, a reliable scheduling policy component allows
tolerating $f$ faults with $f+1$ replicas, while maintaining the long-term
resilience of the service by replacing faulty servers upon round change.

The clients of an ACA algorithm can send their commands to the proposers of any round (in
practice, clients send their commands to proposers of the largest
active round) and servers can use sequences learned in any round
to determine outputs.

ACA specifies the allowed behaviors of the proposers, learners, and switchers
\emph{of a single round}. Similarly to
Chain Agreement, we use the state variables $crashed$, $proposed$,
and, for every learner $l$, $learned\left[ l \right]$.  Additionally,
we use the state variables $inits$, containing the abort sequences
received from the previous round, and $aborts$, containing the abort
sequences transfered to the next round.
Two consecutive ACA rounds are composed by letting the $aborts$ variable of the
first round be the $inits$ variable of the second round.

Initially, $crashed$, $proposed$, for every
learner $l$, $learned\left[ l \right]$, $inits$, and $aborts$ are all empty sets.
The next-state relation consists of five types of transitions. The
first three, $Crash\left( x \right)$, $Propose\left( l, c
\right)$, and $Learn\left( l, cs \right)$, for a learner, proposer, or
switcher $x$, for a learner $l$, and for a sequence of commands
$cs$, have the same effect as in Chain Agreement.
ACA introduces two new transitions, $Init\left(
s, cs \right)$ and $Abort\left( s, cs \right)$, for a switcher $s$ and a sequence of
commands $cs$. The transition $Init\left( s, cs \right)$ adds $cs$ to the set $inits$, and models a switcher receiving the
abort sequence $cs$ from the preceding round.
The transition $Abort\left( s, cs \right)$ adds $cs$ to the set $aborts$ and models a switcher transferring the abort sequence $cs$ to a switcher of the next round.
All the transition are guarded by the following conditions:
\begin{compactitem}
    \item[\textbf{Agreement}:] The elements of the set $\aset{learned'\left[ l
      \right] : l \in Learners}$ form a chain in the partial order.
    \item[\textbf{Validity}:] Every abort sequence or learned sequence
        is of the form $h \star cs$, where $cs$ contains only commands
        of the set $proposed$ and $h$ is the greatest lower bound of a
        nonempty subset of $inits$.
    \item[\textbf{Initialization}:] If $inits$ is empty, then no
        sequence can be learned and no switcher can abort.
    \item[\textbf{Irrevocability}:] In the case of a $Learn\left( l,cs
        \right)$ transition, the new learned sequence $cs$ is a strict
        extension of $Max\left(learned\left[ l \right]\right)$.
        %, $cs
        %\geq Max\left(learned\left[ l \right]\right)$.
    \item[\textbf{Safe Abort}:] Every abort sequence is larger in the
        partial order $\leq$ than every learned sequence.
\end{compactitem}
Note that Agreement and Irrevocability are the same as in Chain
Agreement.

Finally, for every learner $l$, we add a weak fairness condition on the
following state transition: 
\begin{equation}
    \exists  s \in Switchers, cs \in Sequence\left( C \right) : Learn\left( l, cs \right) \vee Abort\left( s,cs \right)
\end{equation}
The weak fairness conditions ensure that when a correct learner has not
learned a sequence containing all commands proposed in the round, then
it eventually learns a new command or, if there is at least one correct switcher, at least one switch value is transfered to the next round. 
Therefore, if a client has submitted a command to a proposer, eventually,
either the client gets a response from the current round, or
the next round is initialized with an abort sequence and the
command can be resubmitted to the next round.

\subsection{The Composition Theorem}

Consider the succession of $n$ rounds numbered $1$ to $n$.  To
distinguish the variables of each round, we annotate the local
variables of each round with the number of the round. For example, the
variables of the seventh round are written $proposed_7$, for every
learner $l$, $learned_7\left[ l \right]$, $inits_7$, and $aborts_7$.

Moreover, we assume that a command, which is proposed to a round and that
is not learned before the first abort sequence is transfered to the
next round, is proposed anew to the next round.

Define the state variable $proposed$ as the union over all rounds $i$
of the $proposed_i$ variables and, for every learner $l$, 
define the $learned\left[ l \right]$ variable as the union over all
rounds $i$ of the $learned_i\left[ l \right]$ variables.

\begin{thm}[Composition Theorem]
    \label{thm:comp}
    In every execution of a succession of ACA rounds, the sequence of valuations
    of the variable $proposed$ and, for every learner $l$, of the variables
    $learned\left[ l \right]$ satisfies Chain Agreement.
\end{thm}
\Cref{thm:comp} can be shown by induction on the number of rounds,
using the following lemma.
\begin{lem}
  \label{lem:comp}
    Consider two rounds numbered $i$ and $i+1$. In every execution of a
    succession of ACA rounds, the sequence of valuations of the variables $inits
    = inits_i$, $propose = proposed_i \cup propose_{i+1}$, for every learner
    $l$, $learned\left[ l \right] = learned_i\left[ l \right] \cup
    learned_{i+1}\left[ l \right]$and $aborts = aborts_{i+1}$ satisfies ACA.
\end{lem}
\begin{proof}
  A mechanically-checked proof in Isabelle/HOL appears in \cref{sec:isaproofs}.
  The proofs uses a version of the specification of ACA that has a more
  executable form that presented in this section. Moreover,
  instead of sequences of commands, the Isabelle/HOL specification uses the more
  general notion of command history, presented in the next subsection.
  The Isabelle/HOL formalization of ACA uses the theory of I/O automata, which
  is also formalized in the Isabelle/HOL. The proof uses a refinement
  mapping from the composition of two consecutive ACA instances to a single ACA
  instance.
\end{proof}

\Cref{thm:comp} guarantees that the successive composition of any
number of ACA rounds implements Chain Agreement.
Therefore, with ACA, one can easily build replicated services that
dynamically adapt to the current operating conditions of the system: a
replicated service has several types of rounds at its disposal, each being
tailored to particular conditions. Each time the conditions change,
the current ACA round aborts and passes the baton to a more 
appropriate type of round, as determined by the scheduling policy. Moreover, a new type
of ACA round can always be devised after the system is deployed and added on the fly to
the existing types of rounds.

We now describe two important practical optimizations of ACA.

\subsection{Histories}
\label{sec:histories}

ACA can be implemented more efficiently by substituting \emph{command histories} for sequences of commands, as in Generalized Consensus \cite{Lamport05GeneralizeConsensus}.

We say that two commands $c_1$ and $c_2$ \emph{commute} when, in every sequential
execution of the service, reversing the order of $c_1$ and $c_2$ does
not change any of the outputs, including those given to $c_1$ and
$c_2$.

A command history, abbreviated history, is a data structure that
represents a set of sequences which are the same modulo the reordering
of commuting commands, and in which duplicate commands do not appear.
All the sequences represented by a given history contain the same
commands and determine the same outputs for each command.  Therefore,
to implement a replicated service, it is sufficient that learners
learn command histories instead of sequences.  For a precise
definition of command histories, we refer the reader to
\cite{Lamport05GeneralizeConsensus}. Our Isabelle/HOL formalization
(\cref{sec:isaproofs}) abstracts
over the concrete representation of histories, assuming only their necessary
properties. Command histories were first
introduced in trace theory \cite{Mazurkiewicz84Semantics}.

A command history can be built by appending a sequence of commands
$cs$ to a history $h$, obtain the history $h \star cs$.  The major
advantage that histories have over sequences is that if a sequence
$cs_1$ is obtained by reordering the commuting commands of $cs_2$,
then $h \star cs_1 = h \star cs_2$. Therefore, in  implementations of
ACA, servers can agree on a history even though
they chose different orders for some commuting commands.

Command histories share the four properties of sequences that are
necessary and sufficient to substitute histories for sequences in the
definition of Chain Agreement and ACA.
\begin{compactitem}
    \item[\textbf{Distinctness}:] No duplicate command appears in a history. 
    \item[\textbf{Ordering}:] Command histories form a partial order:
        $h_1 \leq h_2$ when there exists a sequence $s$ such that $h_2
        = h_1 \star s$.
    \item[\textbf{GLB}:] Every finite set of command histories has a
        \emph{greatest lower bound}.
%    \item[\textbf{LUB}:] Every finite set of compatible command
%        histories has a \emph{least upper bound}, where a set of
%        command histories is compatible when they have a common upper
%        bound.
    \item[\textbf{Consistency}:] If $h_1 \leq h_2 \leq h_3$ and $h_3 =
        h_1 \star s$ then there exists $s'$ and $s''$ where every
        request of $s'$ and $s''$ appears in $s$ and such that $h_2 =
        h_1 \star s'$ and $h_3 = h_2 \star s''$.
\end{compactitem}
The optimized version of ACA is obtained by
simply substituting histories for sequences in the definition of ACA.
The Ordering, GLB, and Consistency properties of histories ensure that
\cref{thm:comp} still holds: the Isabelle/HOL proof of \cref{thm:comp} (see
\cref{sec:isaproofs}) relies only on the four properties above.

\subsection{Optimizing the Execution of Read-Only Commands}
\label{sec:readonly}

Chain Agreement can be further optimized by treating 
read-only commands specially, as in Generalized Lattice Agreement
\cite{FalerioETAL12GeneralizedLatticeAgreement}.

We consider the case in which a set of servers each play the four
roles of proposer, acceptor, learner, and switcher.
Clients sends their commands to any server, which proposes them as a
proposer, and records the command as pending.
%When a server learns a history that contains one of its pending
%commands, it uses the history to determine the response to the pending
%command and forwards the response to the appropriate client.  

As observed in \cite{FalerioETAL12GeneralizedLatticeAgreement}, read-only
commands can be executed faster by directly reading from the last learned
history, instead of proposing the read commands and waiting for it to appear in
a future learned history.  Because learned histories form a chain, all the reads
return consistent values and this approach yields a \emph{serializable}
implementation of the service.

However linearizability is not satisfied if reads are served directly
from the last learned history: a lagging replica server could respond
to a read using a history which does not contain all completed update
commands. To make the executions linearizable without resorting to
proposing read-only commands as normal commands, we can employ the same
technique as in \cite{FalerioETAL12GeneralizedLatticeAgreement}: upon
receiving a read command, a server proposes a special no-op command
that commutes with all other commands; the server then responds to the
read command using the first learned history containing the no-op
command. This ensures that all the commands that had completed before
the read command was issued are present in the history.  Moreover,
since no-op commands commute with all other commands, they can be
treated more efficiently than regular read commands by the acceptors,
like, for example, in a fast round of Fast Paxos.

\section{Fast and Conservative Rounds}
\label{sec:rounds}

Most existing SMR algorithms can easily be obtained as the
composition of one or more ACA rounds. 

The FLP impossibility result \cite{FischerLynchPaterson83ImpossibilityDistributedConsensusOneFaultyProcess}
implies that no algorithm can implement SMR to the letter in practice.
Instead, SMR algorithms guarantee safety (i.e. replica execute the
same sequence of commands) but may not be able to make progress (i.e.
order new commands). To make progress as likely as possible, most SMR
algorithms are structured in consecutive rounds (also called ballots,
views, or epochs). In each round, the algorithm tries to make progress
but cannot be guaranteed to succeed. When the algorithm detects that
progress is no more possible, a new round is started.  The new round
is initialized so as to preserve safety, usually by one of the
acceptors. For example, in Paxos, the leader of a newly started ballot
numbered $i$ determines a value that is \emph{safe at $i$} and
proposes it as first value to the other acceptors of the ballot $i$.
In existing SMR algorithms, new rounds are initialized ad-hoc, which
prevents mixing rounds of two different algorithms.  Instead,
ACA is an abstraction of rounds which establishes a common interface and contract for switching from
one round to the next, enabling switching from any ACA round to any other.

To simplify the task of expressing existing algorithms as the composition of one
or more ACA rounds, we propose two specifications, \emph{conservative ACA
rounds} and
\emph{fast ACA rounds}, which can easily be concretized to obtain executable rounds.
We show that ACA versions of Classic Paxos, Multi-Coordinated Paxos, Chain
Replication, and Ring Paxos can be obtained by concretizing the specification of
conservative ACA rounds, and that ACA versions of the fast rounds of Fast Paxos can be obtained by concretizing the specification of fast ACA rounds.

Fast and conservative ACA rounds are two specifications, at an
intermediate level of abstraction, which satisfy ACA. Both
specifications specify how the state of the acceptors should be
updated but abstract over the particular communication topology used
to implement the state accesses: the specifications use a global state
which is accessible by all servers in all roles. One can refine fast
or conservative rounds by implementing the state accesses and coordination
using the network, obtaining a concrete algorithm.

Conservative and fast ACA rounds are specified using the state variables $inits$, $proposed$, for every learner $l$, $learned\left[ l \right]$
and $aborts$, as in ACA, and, for every acceptor $a$, two new variables
$status\left[ a \right]$, which can be either ``idle'', ``ready'', or
``stopped'' and $hist\left[ a \right]$, the local history of the
acceptor $a$, which can be either a history or the special value $None$.
Initially, $inits$, $aborts$, and, for every learner
$l$, $learned\left[ l \right]$ are empty sets, and, for every acceptor $a$,
$status\left[ a \right]$  is ``idle'' and $hist\left[ a \right]$ is the special
value $None$.

The next-state relations of conservative and fast rounds are composed
of the following types of transitions (and the default $Crash\left( x
\right)$ transition).
\begin{compactitem}
    \item A $Propose\left( p,c \right)$ transition, for a proposer $p$
        and a command $c$, not guarded, inserts $c$ in the set
        $proposed$. 
    \item An $Init\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, not guarded, inserts $h$ in the set $inits$.
    \item A $WakeUp\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``idle''. Its
        effect is to set $hist\left[ a \right]$ to a history found in
        $inits$ and to set $status\left[ a \right]$ to ``ready''.
    \item An $Accept\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``ready'', and
        updates $hist\left[ a \right]$ to $hist\left[ a \right]\star
        c$, where $c$ is a proposed command. In conservative rounds,
        the transition is additionally guarded by the condition that
        the resulting set of local acceptor histories,
        $\aset{hist'\left[ a \right] : a \in Acceptors}$, forms a chain
        in the partial order $\leq$ (this is typically implemented with a
        leader).
    \item A $Learn\left( l, h \right)$ transition, for a learner $l$
      and a history $h$, enabled when $h > learned\left[ l \right]$ and is
      smaller than the GLB of the histories of a learn quorum of acceptors. The effect of
        the transition is to set $learned\left[ l \right]$ to $h$.
    \item A $Stop\left( a \right)$ transition, for an acceptor $a$,
        enabled when $status\left[ a \right]$ is ``ready'', sets
        $status\left[ a \right]$ to ``stopped'' (note that
        $status\left[ a \right] = $ ``stopped'' prevents any further
        ``accept'' transition of acceptor $a$).
%    \item REALLY NEEDED? A $TimeOut\left( a \right)$ transition, for an acceptor $a$,
%        is enabled when $status\left[ a \right]$ is ``idle'' and sets 
%        $status\left[ a \right]$ to ``stopped'' and $hist\left[ a
%        \right]$ to the special value $None$. 
    \item An $Abort\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, is enabled when there exists a abort quorum
        $R$ such that, for every member $a$ of $R$, $status\left[ a
        \right]$ is ``stopped'' and $h \in SafeAborts\left( R
        \right)$. Its effect is to insert  $h$ in the set $aborts$. 
\end{compactitem}

On top of the additional guard on the $Accept$ transition present only
in conservative rounds, conservative and fast ACA rounds differ in
their definition of learn quorums, abort quorums, and in their
definition of the $SafeAborts\left( R \right)$ operator.
To concisely define read and learn quorums, we define 
\begin{equation}
    Q\left( f \right) = \aset{as \subseteq Acceptors :
        Card\left(as\right) \geq \left\lfloor f\times Card\left(
    Acceptors \right)\right\rfloor + 1}.
\end{equation}

In conservative ACA rounds, abort and learn quorums are defined such
that the intersection between two learn quorums is nonempty and the
intersection between a learn quorum and an abort quorum is nonempty.
The definition leads to two interesting cases: $LearnQ = AbortQ =
Q\left( 1/2 \right)$; $LearnQ = \aset{Acceptors}$ and $AbortQ =
\aset{\aset{a} : a \in Acceptors}$. The operator $SafeAborts\left( R
\right)$ is defined as the singleton set containing the maximum
element over the local histories of the acceptors in $R$ which are not
$None$. Note that the maximum exists because conservative rounds
guarantee that the histories of the acceptors form a chain.

In fast ACA rounds, abort and learn quorums are defined such that
the intersection between any two learn quorums is nonempty and the
intersection between any two learn quorums and an abort quorum is
nonempty.  The definition leads to three interesting cases: $LearnQ =
AbortQ = Q\left( 2/3 \right)$; $LearnQ = Q\left( 1/2 \right)$ and
$AbortQ = Q\left( 3/4 \right)$; $LearnQ = \aset{Acceptors}$ and
$AbortQ = \aset{\aset{a : a \in Acceptors}}$.
The operator $SafeAborts\left( R \right)$ is defined as the set of
maximal elements over the set $\aset{GLB\left( \aset{hist\left[ a
\right] : a \in R \cap L \wedge hist\left[ a \right]\neq None} \right)
: L \in LearnQ}$.

The cases in which abort quorums are singleton sets, in both
conservative and fast rounds, allow tolerating
$f$ faults with $f+1$ servers: a round can abort as long as one
acceptor is correct and a new round, possibly using new correct
servers, can take over. Note that changing round cannot happen
without the scheduling policy instructing the switchers about the
identity of the next round, and thus tolerating $f$ faults with
$f+1$ servers relies on the assumption of a reliable scheduling policy.

Define, for every learner $l$, the history variable $\overline{learned}\left[ l \right]$ which is initialized to the empty set and which is
updated each time a new local history is accepted by the learner $l$ by
inserting the new local history in $\overline{learned}\left[ l \right]$ (see \cite{AbadiLamport91ExistenceRefinementMappings} for the
definition of a history variable).
\begin{thm}
  \label{thm:rounds}
    Both conservative and fast ACA rounds implement ACA under the refinement
    mapping that consists in substituting $\overline{learned\left[ l \right]}$
    for $learned\left[ l \right]$.
\end{thm}

\section{Examples of Concrete ACA Algorithms}
\label{sec:examples}

In this section we show how to modify the rounds of Classic Paxos,
Multi-Coordinated Paxos, Chain Replication, Ring Paxos, and Fast Paxos to obtain
ACA rounds. \Cref{thm:comp} then guarantee that all those different types of
rounds can be used in the same algorithm to yield an implementation of Chain
Agreement.

\subsection{Classic Paxos}

The rounds of the Classic Paxos algorithm can be modified so as to
obtain an implementation of conservative ACA rounds.  We define
Classic Paxos ACA rounds by specializing the specification of
conservative ACA rounds, giving a concrete protocol for disseminating
the proposed commands to the acceptors and enforcing that the learned
histories form a chain.

Each Classic Paxos round has a unique leader among the acceptors which
centrally orders the proposed commands, which are accepted by the
other acceptors in the order determined by the leader.  This protocol
ensures that every local acceptor history is a prefix of the local
history of the leader, therefore guaranteeing that the local acceptor histories
forming a chain.

Acceptor broadcast each newly accepted history to the learners, which
learn a history $h$ when they receive enough extensions of $h$ from the
acceptors.  When instructed by the scheduling policy to abort, a
switcher sends a stop message to the acceptors, which irrevocably stop
updating their local history and send back to the switcher an
acknowledgement containing their local history. A switcher
determines an abort history once it has received acknowledgments from
an abort quorum of acceptors $R$, using the operator $SafeAborts\left(
R \right)$.

The specification of Classic Paxos ACA rounds uses the variables of
the specification of conservative ACA rounds, namely the variables
$proposed$, $inits$, $aborts$, the arrays $learned\left[ l \right]$,
$status\left[ a \right]$, and $hist\left[ a \right]$, and two
additional arrays $accepted\left[ l \right]\left[ a \right]$ and
$stop\left[ s \right]\left[ a \right]$, where $l$ is a learner, $a$ is
an acceptor, and $s$ is a switcher.

There is also a network component that we do not describe explicitly.
However, the network allows any servers to communicate by sending and
receiving messages.

Initially, the variables $proposed$, $inits$, $aborts$, and, for every
learner $l$, $learned\left[ l \right]$ are empty sets. For every
acceptor $a$, $status\left[ a \right]$ is ``idle'' and $hist\left[ a
\right]$ is the special value $None$. For every learner $l$ and acceptor $a$,
$accepted\left[ l \right]\left[ a \right]$ is the special value
$None$. For every switcher $s$ and acceptor $a$, $stopped\left[ s
\right]\left[ a \right]$ is set to $false$.  There are initially no
messages in the network.

The next-state relation is composed of the following types of
transitions, where the definitions of learn quorums, abort quorums,
and of the $SafeAborts\left( R \right)$ operator are the ones of conservative
ACA rounds.
\begin{compactitem}
    \item A $Propose\left( p,c \right)$ transition, for a proposer $p$
        and a command $c$, not guarded, inserts $c$ in the set
        $proposed$ and sends the message $\aseq{\quo{prop},c}$ to
        the leader.
    \item An $Init\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, not guarded, inserts $h$ in the set $inits$ and
        sends the message $\aseq{\quo{init},h}$ to the leader.
    \item A $WakeUp\left( leader \right)$ transition, enabled when
        $status\left[ leader \right]$ is ``idle'' and the leader can
        receive a $\aseq{\quo{init},h}$ message. Its effect is to
        receive the message, set $hist\left[ leader \right]$ to $h$,
        to set $status\left[ leader \right]$ to ``ready'', and to
        broadcast the message $\aseq{\quo{leader-accept},h}$ to all
        other acceptors.
    \item An $Accept\left( leader \right)$ transition, enabled when
        $status\left[ leader \right]$ is ``ready'' and the leader can
        receive a $\aseq{\quo{prop},c}$ message. The effect of the
        action is to receive the message, to update $hist\left[ leader
        \right]$ to $hist\left[ leader \right]\star c$, and to
        broadcast the message $\aseq{\quo{ack},hist\left[ leader
        \right]\star c}$ to the learners, and to broadcast the message
        $\aseq{\quo{leader-accept},hist\left[ leader \right]\star c}$
        to all the other acceptors.
    \item An $Accept\left( a \right)$ transition, for an acceptor $a$
        which is not the leader, is enabled when $status\left[ a
        \right]$ is ``ready'' and $a$ can receive a
        $\aseq{\quo{leader-accept},h}$ message where $h > hist\left[ a
        \right]$. The effect of the action is to receive the message,
        to update $hist\left[ a \right]$ to $h$, and to broadcast the
        message $\aseq{\quo{ack},hist\left[ a \right]\star c}$ to the
        learners.
    \item A $RcvAck\left( l \right)$ transition, for a learner $l$, is
        enabled when $l$ can receive a message $\aseq{\quo{ack},h}$
        from an acceptor $a$. Its effect is to receive the message and
        to set $accepted\left[ l \right]\left[ a \right]$ to $h$.
    \item A $Learn\left( l, h \right)$ transition, for a learner $l$
        and a history $h$, is enabled when $h > Max\left(
        learned\left[ l \right] \right)$ and there is a learn quorum
        $Q$ of acceptors such that $h = GLB\left( \aset{accepted\left[
        l \right]\left[ a \right] : a \in Q }\right)$. Its effect is
        to insert $h$ in $learned\left[ l \right]$.
    \item A $Stop\left( s \right)$ transition, for a switcher $s$,
        always enabled, broadcasts a $\aseq{\quo{stop}}$ message to all
        the acceptors.  This transition models a switcher being
        instructed by the scheduling policy to abort the current round.
    \item A $Stop\left( a \right)$ transition, for an acceptor $a$,
        enabled when $a$ can receive a $\aseq{\quo{stop}}$ message
        from a switcher $s$. Its effect is to receive the message, set
        $status\left[ a \right]$ to ``stopped'', and to send the
        message $\aseq{\quo{stopped},hist\left[ a \right]}$ to the
        switcher $s$.
    \item A $RcvStopped\left( s \right)$ transition, for a switcher
        $s$, enabled when $s$ can receive a $\aseq{\quo{stopped},h}$
        message from an acceptor $a$. Its effect is to receive the
        message and to set $stopped\left[ s \right]\left[ a \right]$
        to $h$.
    \item An $Abort\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, is enabled when there exists an abort quorum
        $R$ such that, for every member $a$ of $R$, $stopped\left[ s
        \right]\left[ a \right]$ is not $false$ and $h \in
        SafeAborts\left( R \right)$, where $SafeAborts\left( R
        \right)$ is computed using the array $stopped\left[ a
        \right]$. Its effect is to insert  $h$ in the set $aborts$. 
\end{compactitem}
Compared to the rounds of the original Classic Paxos, Classic Paxos ACA
rounds add an extra level of indirection when changing round: in the
original rounds, the leader of the new round directly queries the
acceptors of the preceeding round, whereas in ACA rounds, the
switchers query the acceptors and then send their abort histories to
the leader. However, changing round is an infrequent event, therefore
this difference should not have much practical impact on performance.
\begin{thm}
  Classic Paxos ACA rounds satisfy Abortable Chain Agreement.
\end{thm}
\begin{proof}
  A Classic Paxos ACA round implements the specification of Abortable
  Chain Agreement under the refinement mapping consisting in
  projecting the state of the round onto the variables $proposed$,
  $inits$, $aborts$, and, for every learner $l$, $learned\left[ l
  \right]$.
\end{proof}

\subsection{Multi-Coordinated Paxos, Chain Replication, and Ring Paxos.}

Multi-Coordinated Paxos, Chain Replication, and Ring Paxos rounds have a similar
structure as Classic Paxos rounds but differ in the way the leader is
implemented and in the way that the histories of the leader are disseminated to
the other acceptors.

Multi-Coordinated Paxos avoids depending on a unique leader by using a
distributed leader implementation that can make progress as long as a
strict majority of the acceptors are correct, trading off resilience
for a higher time complexity. Conservative ACA
rounds can be implemented like with Classic Paxos, replacing the
leader by the distributed leader of Multi-Coordinated Paxos.

In Chain Replication, acceptors are arranged in a chain whose head is
the leader of the round. As in Classic Paxos, abort histories and
proposed commands are sent to the leader. However, instead of the
leader directly sending its local history to all the other acceptors,
the local history of the leader is
forwarded along the chain from one acceptor to the other until it
reaches the last acceptor, which sends the history to the learners. 
By spreading the load more evenly on the all the servers, Chain Replication
can achieve higher throughput that Classic Paxos.
Conservative ACA rounds can be implemented like with Classic Paxos,
replacing the broadcast of the leader by the propagation of the leader's history
along the chain of servers.

Ring Paxos optimizes Chain Replication by having the leader broadcast
commands to the acceptors using IP multicast and only sending hashes
of the commands along the chain. Ring Paxos round can be modified to implement
conservative ACA rounds in a similar way as for Chain Replication.

\subsection{Fast Paxos}

Fast Paxos is composed of two types of rounds: classic rounds, like in Classic
Paxos, and fast rounds.
The fast rounds can be transformed into
implementations of fast ACA rounds. Instead of sending their
commands to a leader, as in Classic Paxos, the proposers of fast
rounds directly broadcast their commands to all the acceptors. As long
as commands are received in the same order by a learn quorum of
acceptors or are received in different orders but commute, commands can be learned in two message-propagation delays instead of three in Classic Paxos.
However, if non-commuting commands are received in different orders by
several acceptors, the local history of the acceptors may not form a
chain anymore and the rounds must abort. The fast rounds of Fast
Paxos implement fast ACA rounds.

Fast Paxos ACA rounds are specified using the same set of variables as for
Classic Paxos, initialized to the same values.
The next-state relation is composed of the following types of
transitions, where the definitions of learn quorums, abort quorums,
and of the $SafeAborts\left( R \right)$ operator are the ones of fast
ACA rounds.
\begin{compactitem}
    \item A $Propose\left( p,c \right)$ transition, for a proposer $p$
        and a command $c$, not guarded, inserts $c$ in the set
        $proposed$ and broadcasts the message $\aseq{\quo{prop},c}$ to
        all the acceptors.
    \item An $Init\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, not guarded, inserts $h$ in the set $inits$ and
        broadcasts the message $\aseq{\quo{init},h}$ to all the acceptors.
    \item A $WakeUp\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``idle'' and $a$
        can receive an $\aseq{\quo{init},h}$ message. Its effect is to
        receive the message, set $hist\left[ a \right]$ to $h$, and to
        set $status\left[ a \right]$ to ``ready''.
    \item An $Accept\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``ready'' and $a$
        can receive a $\aseq{\quo{prop},c}$ message. The effect of the
        action is to receive the message, to update $hist\left[ a
        \right]$ to $hist\left[ a \right]\star c$, and to broadcast
        the message $\aseq{\quo{ack},hist\left[ a \right]\star c}$ to
        the learners.
    \item The $RcvAck\left( l \right)$ transitions, for a learner $l$,
        the $Learn\left( l, h \right)$ transitions, for a learner $l$
        and a history $h$, the $Stop\left( s \right)$ transitions, for
        a switcher $s$, $Stop\left( a \right)$ transitions, for an
        acceptor $a$, the $RcvStopped\left( s \right)$ transitions,
        for a switcher $s$, and the $Abort\left( s, h \right)$
        transitions, for a switcher $s$ and a history $h$, which are
        all the same as in Classic Paxos ACA rounds.
\end{compactitem}

As for Classic Paxos ACA rounds, Fast Paxos ACA rounds implement ACA
under the refinement mapping consisting projecting the state of the
round onto the variables $proposed$, $inits$, $aborts$, and, for every
learner $l$, $learned\left[ l \right]$.


\newpage

\printbibliography


\begin{appendix}
  
  \label{sec:isaproofs}
 
%  \includepdf[pages={1},pagecommand={\section{Mechanical Proof of the
%  Composition Theorem in Isabelle/HOL}\label{sec:isaproofs}},scale=1]{../IsabellePDFS/podctheories.pdf}
%  \includepdf[pages={2-},pagecommand={},scale=1]{../IsabellePDFS/podctheories.pdf}
  
\end{appendix}

\end{document}
    We present a new abstraction, Abortable Generalized Consensus, which enables the
    correct-by-construction composition of heterogeneous State-Machine
    Replication algorithms.

    integrating state of the art techniques to optimize executions.  ACA is the most complete approach to date enabling the
    correct-by-construction composition of heterogeneous State-Machine
    Replication algorithms. We provide two specifications satisfying
    ACA and we illustrate their power by refining them to
    obtain a versatile adaptive algorithm that combines five existing
    algorithms into a single one. ACA is completely formalized and its
    underlying composition theorem has been mechanically checked by an interactive
    proof assistant.
}

\vspace{2cm}

\begin{center}
This paper is a regular submission.

\vspace{1cm}
This paper is a student paper.
\end{center}

\newpage

\section{Introduction}

The State-Machine Replication technique (abbreviated SMR) allows
building reliable services on top of unreliable hardware. The basic idea is to 
replicate a service over several servers, each executing the same
sequence of (deterministic) commands. 
Making SMR algorithms efficient has been a long-standing
challenge and a multitude of algorithms have been proposed. Examples
include Fast Paxos \cite{Lamport06FastPaxos}, Disk Paxos
\cite{GafniLamport03DiskPaxos}, Chain Replication
\cite{RenesseSchneider04ChainReplicationSupportingHighThroughputAvailability},
Ring Paxos
\cite{MarandiETAL10RingPaxosHighthroughputAtomicBroadcastProtocol},
Egalitarian Paxos
\cite{MoraruAndersenKaminsky13ThereIsMoreConsensusEgalitarianParliaments},
Multi-Coordinated Paxos
\cite{CamargosSchmidtPedone07MulticoordinatedPaxos}, Cheap Paxos
\cite{LamportMassa04CheapPaxos}, Vertical Paxos
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication},
Paxos-MIC
\cite{HurfinMoiseNarzul11AdaptiveFastPaxosMakingQuickEverlasting},
Mencius
\cite{MaoJunqueiraMarzullo08MenciusBuildingEfficientReplicatedStateMachine},
and Fast Mencius \cite{WeiETAL13FastMenciusMenciusLowCommitLatency}.

Each of the existing algorithms is best suited to a particular range
of environments, characterized, e.g., by client load, network
topology, likelihood of faults, communication latency and bandwidth, processing
power of nodes, availability of disk storage and memory.
However, the environment faced by real systems evolves over time:
hardware is upgraded, new data-centers are built, the popularity of a
service changes, etc.  Consistent performance therefore comes with
adaptation to change.  Unfortunately, existing SMR algorithms cannot easily be
stopped and replaced by another algorithm on the fly. Moreover,
devising a new algorithm that can change behavior dynamically is hard:
dynamically switching from one SMR algorithm to another requires
synchronizing notoriously intricate algorithms.

We propose a new abstraction, \emph{Abortable Chain Agreement}
(abbreviated ACA), which subsumes SMR and whose implementations,
called \emph{ACA rounds}, can, by construction, pass the baton from
one to another on the fly and efficiently. Moreover, optimizing a replicated
service consisting of several ACA rounds becomes just a matter of devising a new
ACA round, which can then be plugged-in on the fly: any new ACA round
is compatible with every existing ACA round by construction.

Abortable Chain Agreement is the \emph{most complete framework to date} enabling
correct by construction composition of heterogeneous rounds.  
ACA is completely formalized and its underlying composition theorem has been
mechanically checked by an interactive proof assistant.  
Compared to ACA,
existing approaches
\cite{BarNoyETAL87ShiftingGearsChangingAlgorithmsFlyTo,GuerraouiETAL10Next700BftProtocols,GuerraouiKuncakLosa12SpeculativeLinearizability}
are limited. In particular, they do not allow the disorderly execution of
commuting and read-only commands, an important practical optimization
which is at the root of recent work on SMR like Generalized Consensus
\cite{Lamport05GeneralizeConsensus} and Generalized Lattice Agreement
\cite{FalerioETAL12GeneralizedLatticeAgreement}.

\begin{comment}
On top of the traditional roles of proposer, acceptor, and learners
\cite{lamport2001paxos} used in consensus algorithms, ACA introduces
the notion of \emph{switchers} and of \emph{scheduling policy}. The switchers
have the task of aborting a running ACA round and initializing a new
ACA round in a safe and live manner.  The \emph{scheduling policy}
decides when to abort an ACA round and choses the next ACA round to
execute. It must ensure that all switchers agree on the next ACA round
to initialize.
\end{comment}

We observe that, because of the FLP impossibility result
\cite{FischerLynchPaterson83ImpossibilityDistributedConsensusOneFaultyProcess},
most existing SMR algorithms are structured in a sequence of abortable
rounds which can easily be transformed into ACA rounds. To simplify
this task even further, we propose two specifications, \emph{conservative
ACA rounds} and \emph{fast ACA rounds}, which, as we show, can be concretized
to obtain ACA versions of the rounds of five existing algorithms: 
Classic Paxos, Fast Paxos, Chain Replication, Ring Paxos,
and Multi-Coordinated Paxos. ACA guarantees that the composition of the five ACA
rounds is correct by construction, forming a versatile adaptive replication
algorithm. 

The rest of the paper is structured as follows.
\Cref{sec:related} surveys recent related work. \Cref{sec:ca} presents Chain
Agreement, which embodies the requirements for implementing SMR. \Cref{sec:aca}
presents Abortable Chain Agreement and its optimizations to treat commuting
and read-only commands efficiently. \Cref{sec:rounds} presents our specification
of conservative and fast ACA rounds, which implement ACA. In
\cref{sec:examples}, we show that the rounds of  
Classic Paxos, Fast Paxos, Chain Replication, Ring Paxos,
and Multi-Coordinated Paxos can easily be transformed into ACA implementations
by using our specifications of conservative and fast ACA rounds.
Finally, in \cref{sec:isaproofs}, we provide a complete formalization of ACA
and a mechanical proof of the \emph{composition theorem} (\cref{thm:comp}),
checked by the interactive proof assistant Isabelle/HOL \cite{NipkowPaulsonWenzel02IsabelleHOL}. 

\begin{comment}
Abortable Chain Agreement builds on several recent advances in SMR
algorithms: ACA allows acceptors to only eventually reach agreement,
like in Generalized Paxos \cite{Lamport05GeneralizeConsensus},
boosting performance when most commands commute; ACA allows fast
execution of read commands like in Generalized Lattice Agreement
\cite{FalerioETAL12GeneralizedLatticeAgreement}; ACA implementations
can tolerate $f$ faults with only $f+1$ replicas and replace crashed replicas
upon changing round, as in Vertical Paxos  \cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication}.  
\end{comment}

\section{Related Work}
\label{sec:related}

SMR is often implemented using a sequence of instances of Consensus.
There are numerous examples of consensus algorithms in the literature.
However, Abortable Chain Agreement is based on Generalized Consensus. 
In Generalized Consensus \cite{Lamport05GeneralizeConsensus}, the learners of a
SMR algorithm repeatedly learn new values belonging to a \emph{C-struct set}. A
C-struct can be seen as a data structure encoding  sequences of commands modulo
the ordering of commands that commute. The advantage of Generalized
Consensus over Consensus is that
two servers which receive commuting commands in different orders can still reach
agreement on C-structs without further synchronization. 
Our Abortable Chain Agreement can also use C-structs, with the same advantages
as Generalized Consensus. For simplicity, the presentation in this
paper uses the more concrete notion of \emph{command history} (see
\cref{sec:histories}).

Generalized Lattice Agreement \cite{FalerioETAL12GeneralizedLatticeAgreement} allows more efficient implementations of SMR when
commands are partitioned into read-only commands and write-only commands.
Abortable Chain Agreement supports the same optimizations as Generalized Lattice Agreement.
Notably, read-only commands are treated specially so as to optimize their
executions (see \cref{sec:readonly}).

Vertical Paxos algorithms 
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication} are SMR algorithms
whose set of replica servers can be reconfigured without stopping to process new
commands. Crashed servers can therefore be replaced by new servers, ensuring the
long-term availability of a replicated service.
Vertical Paxos algorithms use an external reconfiguration master, itself
implemented as a replicated state machine, which determines the servers that should
be removed from or added to the configuration.
ACA shares some aspects of Vertical Paxos algorithms: the task of the
reconfiguration master is similar to the task of the scheduling policy
component of ACA (see \cref{sec:aca}).
However, in ACA, changing round can be used not only to replace crashed servers
but also to change the algorithm that the servers are running. 
Changing algorithm is not possible in Vertical Paxos.
In both Vertical Paxos and ACA, a reliable reconfiguration master, resp. a
reliable scheduling policy, allows tolerating $f$ crashes with $f+1$ servers.

The Abstract Framework \cite{GuerraouiETAL10Next700BftProtocols} proposes to
build Byzantine Fault-Tolerant algorithms as the succession of abortable rounds
called Abstract instances. Abstract instances must satisfy the Abstract
correctness properties. By construction, the composition of any number of
Abstract instances is a correct SMR implementation. However, the Abstract
Framework uses totally ordered sequence of commands, making difficult the
optimization of the execution of commuting and read-only commands that are
possible with ACA.  Moreover, the Abstract Framework does not identify the
crucial role of the scheduling policy for the long-term resilience of a service.
Abortable Chain Agreement combines the ideas of the Abstract Framework,
Generalized Paxos, Generalized Lattice Agreement, and Vertical Paxos in a
unified abstraction. 

Finally, the Speculative Linearizability framework
\cite{GuerraouiKuncakLosa12SpeculativeLinearizability} was a first
attempt by the authors of the present paper at generalizing the
Abstract Framework and mechanically proving its properties with the
Isabelle/HOL interactive
proofs assistant.  Like the Abstract Framework, the
Speculative Linearizability framework is based on totally ordered
sequences of commands, with the same drawback for the execution of
commuting and read-only commands. Moreover, Abortable Chain Agreement is both
conceptually simpler and subsumes the Speculative Linearizability
property.  Like Speculative Linearizability, Abortable Chain Agreement
and its main property, the composition theorem (\cref{thm:comp}), are
formalized in Isabelle/HOL (see \cref{sec:isaproofs}).

Abortable Chain Agreement is the most complete framework to date for building
adaptive replication algorithms out of heterogeneous rounds, making state of the
art optimization techniques available to algorithm designers, which was not
possible before.

\section{Chain Agreement}
\label{sec:ca}

We consider a set of asynchronous servers communicating by message passing in an
asynchronous network. Servers are not necessarily sequential processes. We
describe a behavior of the system using an infinite sequence of states, where a
state is a function from variable names to values (i.e. a valuation
of variables).  We specify sets of allowed behaviors using an initial predicate,
a next-state relation (using unprimed and primed variables) and a fairness
condition, all in the style of TLA+ \cite{Lamport02SpecifyingSystems}. However,
for succinctness, our specification are rather informal, eluding non-essential
details.

Our specifications all contain by default a state variable $crashed$ and
$Crash\left( x \right)$ transition which is always enabled. A server $x$ faithfully
executes the algorithm that is assigned to it until its identifier is added to
the variable $crashed$ by a $Crash\left( x \right)$ transitions.  When the identifier of a
server is in the set $crashed$, all its actions are disabled.  In an execution,
a server that is never added to the set $crashed$ is said correct.

We consider a computing service exposing a set of commands $C$. The
service has a sequential specification consisting of an initial state
and a deterministic transition relation in which every command
atomically updates the state of the service and produces an output. We
assume that duplicate commands have no effect on the state of the
service and return the same output as their first occurrence.

In a traditional SMR algorithm, the servers can be seen has playing one or
several of three roles: \emph{proposers}, which propose new commands to execute,
\emph{acceptors}, which accept and order commands in a sequence, and
\emph{learners}, which learn about the growing sequence of commands to
execute \cite{lamport2001paxos}. Often, but not necessarily, every replica server plays the
three roles of proposer, acceptor, and learner: clients of the service
send their commands to some replica servers; replica servers submit
the received commands to the SMR protocol in the role of proposers;
replica servers respond to commands by executing the commands learned
in the role of learners; replica servers participate in command
ordering in the role of acceptors.  An SMR algorithm guarantees that
the replicas learn the same sequences of commands, possibly up to the
reordering of commuting commands. Therefore, every learner can respond to client
requests using its last learned sequence of commands, and clients will receive
the same responses as the ones produces by a centralized, non-replicated,
service. 

Chain Agreement precisely specifies the allowed behaviors of the roles of \emph{proposers}
and \emph{learners}, abstracting over the behavior of acceptors. 

\begin{comment}
We suppose that each server can play a number of \emph{roles}.
Chain Agreement specifies the allowed behaviors the roles of \emph{proposers}
and \emph{learners}. Proposers receive commands from the clients of the service
and propose them for execution by the replicated service. Each learner learns about
a growing sequence of commands. Thanks to the sequential specification of the
service, a sequence of commands determines an output for each the included commands. 
In a traditional SMR algorithm, servers can also play the role of
\emph{acceptors}, whose task is to collectively order commands and let the
learners know about the latest sequence of ordered commands.

The point of Chain Agreement is to implement a replicated service by having every learner learn about a growing sequence of commands, which
represent an execution of the sequential specification of the service.
Crucially, at all times, the sequences of commands learned by the
different learners must form a chain in the prefix order on sequences.
Moreover, for every command $c$ proposed by a correct proposer, every
correct learner must eventually learn a sequence containing $c$.  Once
a learner learns about a sequence containing a command $c$, it can
determine the output produced by $c$, using the sequential
specification of the service, and respond to the client that issued
the command $c$.
\end{comment}

To specify Chain Agreement, we need the notion of ordering of sequences and of
maximum sequence.  The prefix order on sequences is denoted by the operator
$\leq$ ($s_1 \leq s_2$ means that $s_1$ is a prefix of $s_2$). 
%Using the operator $\leq$, we define $\geq$, $<$, and $>$ as expected. 
Note that $\leq$ is a partial order on sequences. The maximum over a set of
sequences $S$ is denoted by $Max\left( S \right)$ and $Max\left( \aset{}
\right)$ is the empty sequence.

We specify Chain Agreement using the state variables $crashed$, $proposed$, containing the proposed commands,
and, for every learner $l$,  $learned\left[ l \right]$, a set of
sequences of commands. Initially, $crashed$, $proposed$ and, for every learner $l$,
$learned\left[ l \right]$ are empty sets. 
Remember that any transition involving a server $x$ is always disabled when $x\in crashed$. 

The next-state relation consists of three types of transitions:
$Crash\left( x \right)$ transitions; $Propose\left( l, c
\right)$ transitions, for a learner $l$ and a command $c$, in which
$c$ is inserted in the set $proposed$; $Learn\left( l,cs \right)$
transitions, for a learner $l$ and a sequence of commands $cs$, in
which $cs$ is inserted in $learned\left[ l \right]$. 
A $Learn\left( l, cs \right)$ transition is guarded by the following
conditions:
\begin{compactitem}
    \item[\textbf{Agreement}:] The elements of the set $\aset{learned'\left[ l
      \right] : l \in Learners}$, the learned sequences after the transition,
      form a chain in the partial order $\leq$.
    \item[\textbf{Validity}:] Every learned sequence contains only
        proposed commands.  
    \item[\textbf{Irrevocability}:] The new learned sequence
        $cs$ is a strict extension of $Max\left(learned\left[ l
        \right]\right)$. 
        %\\ $cs > Max\left(learned\left[ l \right]\right)$.
\end{compactitem}
Finally, we add, for every learner $l$, one weak fairness condition
\cite{Lamport02SpecifyingSystems} on the transitions $Learn\left( l,
cs \right)$. The weak fairness conditions ensure that every correct
learner eventually learns about every proposed command.

Thanks to the properties of Chain Agreement, the clients, observing
their input commands and the received responses, see a
\emph{linearizable} execution
\cite{HerlihyWing90LinearizabilityCorrectnessConditionConcurrentObjects}.
Moreover, the service remains available as long as at least one
proposer and one learner are correct.

\section{Abortable Chain Agreement}
\label{sec:aca}

We now consider implementing Chain Agreement as a sequence of \emph{Abortable Chain
Agreement rounds}, where each round makes progress ordering requests or aborts
its execution and passes the baton to the next round in the sequence.
An algorithm composed of a sequence of ACA rounds is called an \emph{ACA
algorithm}.

On top of the traditional roles of proposer, acceptor, and learner, ACA
introduces the new role of \emph{switcher} and a new component, the
\emph{scheduling policy}. In ACA, the assignment of the roles of proposer,
acceptor, learner, and switcher can change in each rounds, allowing for
reconfiguration. 
In normal circumstances, the proposers, acceptors,
and learners of an ACA round work together to implement Chain Agreement.
However, if the environment becomes unfavorable to a running ACA round, the
scheduling policy can instruct the round to abort its execution and pass the
baton, using the switchers, to a new round.

A switcher of an aborting round determines, from the state of the
acceptors, an \emph{abort sequence} that it transfers to one or several
switchers of the new round.  Upon receiving an abort sequence, a switcher of the
new round initializes the acceptors of the new round, which can then
proceed implementing SMR, until the new round itself aborts and the
process is repeated. 
We assume that in the first round, which has no previous round, every 
switchers receives the empty abort sequence.

The scheduling policy determines when to abort an ACA round and which new ACA
round should take over. The scheduling policy must inform the switchers about the
identity of the next round and must guarantee that all switchers receive the
same information.  In this paper we abstract over the scheduling policy, assuming
that a round that aborts passes the baton a nondeterministically chosen new
round. A reliable scheduling-policy component can realistically be implemented
as a replicated state machine running on a large number of servers otherwise
dedicated to other tasks
\cite{LamportMalkhiZhou09VerticalPaxosPrimarybackupReplication}. We will see
 in \cref{sec:rounds} that, as in Vertical Paxos, a reliable scheduling policy component allows
tolerating $f$ faults with $f+1$ replicas, while maintaining the long-term
resilience of the service by replacing faulty servers upon round change.

The clients of an ACA algorithm can send their commands to the proposers of any round (in
practice, clients send their commands to proposers of the largest
active round) and servers can use sequences learned in any round
to determine outputs.

ACA specifies the allowed behaviors of the proposers, learners, and switchers
\emph{of a single round}. Similarly to
Chain Agreement, we use the state variables $crashed$, $proposed$,
and, for every learner $l$, $learned\left[ l \right]$.  Additionally,
we use the state variables $inits$, containing the abort sequences
received from the previous round, and $aborts$, containing the abort
sequences transfered to the next round.
Two consecutive ACA rounds are composed by letting the $aborts$ variable of the
first round be the $inits$ variable of the second round.

Initially, $crashed$, $proposed$, for every
learner $l$, $learned\left[ l \right]$, $inits$, and $aborts$ are all empty sets.
The next-state relation consists of five types of transitions. The
first three, $Crash\left( x \right)$, $Propose\left( l, c
\right)$, and $Learn\left( l, cs \right)$, for a learner, proposer, or
switcher $x$, for a learner $l$, and for a sequence of commands
$cs$, have the same effect as in Chain Agreement.
ACA introduces two new transitions, $Init\left(
s, cs \right)$ and $Abort\left( s, cs \right)$, for a switcher $s$ and a sequence of
commands $cs$. The transition $Init\left( s, cs \right)$ adds $cs$ to the set $inits$, and models a switcher receiving the
abort sequence $cs$ from the preceding round.
The transition $Abort\left( s, cs \right)$ adds $cs$ to the set $aborts$ and models a switcher transferring the abort sequence $cs$ to a switcher of the next round.
All the transition are guarded by the following conditions:
\begin{compactitem}
    \item[\textbf{Agreement}:] The elements of the set $\aset{learned'\left[ l
      \right] : l \in Learners}$ form a chain in the partial order.
    \item[\textbf{Validity}:] Every abort sequence or learned sequence
        is of the form $h \star cs$, where $cs$ contains only commands
        of the set $proposed$ and $h$ is the greatest lower bound of a
        nonempty subset of $inits$.
    \item[\textbf{Initialization}:] If $inits$ is empty, then no
        sequence can be learned and no switcher can abort.
    \item[\textbf{Irrevocability}:] In the case of a $Learn\left( l,cs
        \right)$ transition, the new learned sequence $cs$ is a strict
        extension of $Max\left(learned\left[ l \right]\right)$.
        %, $cs
        %\geq Max\left(learned\left[ l \right]\right)$.
    \item[\textbf{Safe Abort}:] Every abort sequence is larger in the
        partial order $\leq$ than every learned sequence.
\end{compactitem}
Note that Agreement and Irrevocability are the same as in Chain
Agreement.

Finally, for every learner $l$, we add a weak fairness condition on the
following state transition: 
\begin{equation}
    \exists  s \in Switchers, cs \in Sequence\left( C \right) : Learn\left( l, cs \right) \vee Abort\left( s,cs \right)
\end{equation}
The weak fairness conditions ensure that when a correct learner has not
learned a sequence containing all commands proposed in the round, then
it eventually learns a new command or, if there is at least one correct switcher, at least one switch value is transfered to the next round. 
Therefore, if a client has submitted a command to a proposer, eventually,
either the client gets a response from the current round, or
the next round is initialized with an abort sequence and the
command can be resubmitted to the next round.

\subsection{The Composition Theorem}

Consider the succession of $n$ rounds numbered $1$ to $n$.  To
distinguish the variables of each round, we annotate the local
variables of each round with the number of the round. For example, the
variables of the seventh round are written $proposed_7$, for every
learner $l$, $learned_7\left[ l \right]$, $inits_7$, and $aborts_7$.

Moreover, we assume that a command, which is proposed to a round and that
is not learned before the first abort sequence is transfered to the
next round, is proposed anew to the next round.

Define the state variable $proposed$ as the union over all rounds $i$
of the $proposed_i$ variables and, for every learner $l$, 
define the $learned\left[ l \right]$ variable as the union over all
rounds $i$ of the $learned_i\left[ l \right]$ variables.

\begin{thm}[Composition Theorem]
    \label{thm:comp}
    In every execution of a succession of ACA rounds, the sequence of valuations
    of the variable $proposed$ and, for every learner $l$, of the variables
    $learned\left[ l \right]$ satisfies Chain Agreement.
\end{thm}
\Cref{thm:comp} can be shown by induction on the number of rounds,
using the following lemma.
\begin{lem}
  \label{lem:comp}
    Consider two rounds numbered $i$ and $i+1$. In every execution of a
    succession of ACA rounds, the sequence of valuations of the variables $inits
    = inits_i$, $propose = proposed_i \cup propose_{i+1}$, for every learner
    $l$, $learned\left[ l \right] = learned_i\left[ l \right] \cup
    learned_{i+1}\left[ l \right]$and $aborts = aborts_{i+1}$ satisfies ACA.
\end{lem}
\begin{proof}
  A mechanically-checked proof in Isabelle/HOL appears in \cref{sec:isaproofs}.
  The proofs uses a version of the specification of ACA that has a more
  executable form that presented in this section. Moreover,
  instead of sequences of commands, the Isabelle/HOL specification uses the more
  general notion of command history, presented in the next subsection.
  The Isabelle/HOL formalization of ACA uses the theory of I/O-automata, which
  is also formalized in the Isabelle/HOL development. The proof uses a refinement
  mapping from the composition of two consecutive ACA instances to a single ACA
  instance.
\end{proof}

\Cref{thm:comp} guarantees that the successive composition of any
number of ACA rounds implements Chain Agreement.
Therefore, with ACA, one can easily build replicated services that
dynamically adapt to the current operating conditions of the system: a
replicated service has several types of rounds at its disposal, each being
tailored to particular conditions. Each time the conditions change,
the current ACA round aborts and passes the baton to a more 
appropriate type of round, as determined by the scheduling policy. Moreover, a new type
of ACA round can always be devised after the system is deployed and added on the fly to
the existing types of rounds.

We now describe two important practical optimizations of ACA.

\subsection{Histories}
\label{sec:histories}

ACA can be implemented more efficiently by substituting \emph{command histories} for sequences of commands, as in Generalized Consensus \cite{Lamport05GeneralizeConsensus}.

We say that two commands $c_1$ and $c_2$ \emph{commute} when, in every sequential
execution of the service, reversing the order of $c_1$ and $c_2$ does
not change any of the outputs, including those given to $c_1$ and
$c_2$.

A command history, abbreviated history, is a data structure that
represents a set of sequences which are the same modulo the reordering
of commuting commands, and in which duplicate commands do not appear.
All the sequences represented by a given history contain the same
commands and determine the same outputs for each command.  Therefore,
to implement a replicated service, it is sufficient that learners
learn command histories instead of sequences.  For a precise
definition of command histories, we refer the reader to
\cite{Lamport05GeneralizeConsensus}. Our Isabelle/HOL formalization
(\cref{sec:isaproofs}) abstracts
over the concrete representation of histories, assuming only their necessary
properties. Command histories were first
introduced in trace theory \cite{Mazurkiewicz84Semantics}.

A command history can be built by appending a sequence of commands
$cs$ to a history $h$, obtain the history $h \star cs$.  The major
advantage that histories have over sequences is that if a sequence
$cs_1$ is obtained by reordering the commuting commands of $cs_2$,
then $h \star cs_1 = h \star cs_2$. Therefore, in  implementations of
ACA, servers can agree on a history even though
they chose different orders for some commuting commands.

Command histories share the four properties of sequences that are
necessary and sufficient to substitute histories for sequences in the
definition of Chain Agreement and ACA.
\begin{compactitem}
    \item[\textbf{Distinctness}:] No duplicate command appears in a history. 
    \item[\textbf{Ordering}:] Command histories form a partial order:
        $h_1 \leq h_2$ when there exists a sequence $s$ such that $h_2
        = h_1 \star s$.
    \item[\textbf{GLB}:] Every finite set of command histories has a
        \emph{greatest lower bound}.
%    \item[\textbf{LUB}:] Every finite set of compatible command
%        histories has a \emph{least upper bound}, where a set of
%        command histories is compatible when they have a common upper
%        bound.
    \item[\textbf{Consistency}:] If $h_1 \leq h_2 \leq h_3$ and $h_3 =
        h_1 \star s$ then there exists $s'$ and $s''$ where every
        request of $s'$ and $s''$ appears in $s$ and such that $h_2 =
        h_1 \star s'$ and $h_3 = h_2 \star s''$.
\end{compactitem}
The optimized version of ACA is obtained by
simply substituting histories for sequences in the definition of ACA.
The Ordering, GLB, and Consistency properties of histories ensure that
\cref{thm:comp} still holds: the Isabelle/HOL proof of \cref{thm:comp} (see
\cref{sec:isaproofs}) relies only on the four properties above.

\subsection{Optimizing the Execution of Read-Only Commands}
\label{sec:readonly}

Chain Agreement can be further optimized by treating 
read-only commands specially, as in Generalized Lattice Agreement
\cite{FalerioETAL12GeneralizedLatticeAgreement}.

We consider the case in which a set of servers each play the four
roles of proposer, acceptor, learner, and switcher.
Clients sends their commands to any server, which proposes them as a
proposer, and records the command as pending.
%When a server learns a history that contains one of its pending
%commands, it uses the history to determine the response to the pending
%command and forwards the response to the appropriate client.  

As observed in \cite{FalerioETAL12GeneralizedLatticeAgreement}, read-only
commands can be executed faster by directly reading from the last learned
history, instead of proposing the read commands and waiting for it to appear in
a future learned history.  Because learned histories form a chain, all the reads
return consistent values and this approach yields a \emph{serializable}
implementation of the service.

However linearizability is not satisfied if reads are served directly
from the last learned history: a lagging replica server could respond
to a read using a history which does not contain all completed update
commands. To make the executions linearizable without resorting to
proposing read-only commands as normal commands, we can employ the same
technique as in \cite{FalerioETAL12GeneralizedLatticeAgreement}: upon
receiving a read command, a server proposes a special no-op command
that commutes with all other commands; the server then responds to the
read command using the first learned history containing the no-op
command. This ensures that all the commands that had completed before
the read command was issued are present in the history.  Moreover,
since no-op commands commute with all other commands, they can be
treated more efficiently than regular read commands by the acceptors,
like, for example, in a fast round of Fast Paxos.

\section{Fast and Conservative Rounds}
\label{sec:rounds}

Most existing SMR algorithms can easily be obtained as the
composition of one or more ACA rounds. 

The FLP impossibility result \cite{FischerLynchPaterson83ImpossibilityDistributedConsensusOneFaultyProcess}
implies that no algorithm can implement SMR to the letter in practice.
Instead, SMR algorithms guarantee safety (i.e. replica execute the
same sequence of commands) but may not be able to make progress (i.e.
order new commands). To make progress as likely as possible, most SMR
algorithms are structured in consecutive rounds (also called ballots,
views, or epochs). In each round, the algorithm tries to make progress
but cannot be guaranteed to succeed. When the algorithm detects that
progress is no more possible, a new round is started.  The new round
is initialized so as to preserve safety, usually by one of the
acceptors. For example, in Paxos, the leader of a newly started ballot
numbered $i$ determines a value that is \emph{safe at $i$} and
proposes it as first value to the other acceptors of the ballot $i$.
In existing SMR algorithms, new rounds are initialized ad-hoc, which
prevents mixing rounds of two different algorithms.  Instead,
ACA is an abstraction of rounds which establishes a common interface and contract for switching from
one round to the next, enabling switching from any ACA round to any other.

To simplify the task of expressing existing algorithms as the composition of one
or more ACA rounds, we propose two specifications, \emph{conservative ACA
rounds} and
\emph{fast ACA rounds}, which can easily be concretized to obtain executable rounds.
We show that ACA versions of Classic Paxos, Multi-Coordinated Paxos, Chain
Replication, and Ring Paxos can be obtained by concretizing the specification of
conservative ACA rounds, and that ACA versions of the fast rounds of Fast Paxos can be obtained by concretizing the specification of fast ACA rounds.

Fast and conservative ACA rounds are two specifications, at an
intermediate level of abstraction, which satisfy ACA. Both
specifications specify how the state of the acceptors should be
updated but abstract over the particular communication topology used
to implement the state accesses: the specifications use a global state
which is accessible by all servers in all roles. One can refine fast
or conservative rounds by implementing the state accesses and coordination
using the network, obtaining a concrete algorithm.

Conservative and fast ACA rounds are specified using the state variables $inits$, $proposed$, for every learner $l$, $learned\left[ l \right]$
and $aborts$, as in ACA, and, for every acceptor $a$, two new variables
$status\left[ a \right]$, which can be either ``idle'', ``ready'', or
``stopped'' and $hist\left[ a \right]$, the local history of the
acceptor $a$, which can be either a history or the special value $None$.
Initially, $inits$, $aborts$, and, for every learner
$l$, $learned\left[ l \right]$ are empty sets, and, for every acceptor $a$,
$status\left[ a \right]$  is ``idle'' and $hist\left[ a \right]$ is the special
value $None$.

The next-state relations of conservative and fast rounds are composed
of the following types of transitions (and the default $Crash\left( x
\right)$ transition).
\begin{compactitem}
    \item A $Propose\left( p,c \right)$ transition, for a proposer $p$
        and a command $c$, not guarded, inserts $c$ in the set
        $proposed$. 
    \item An $Init\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, not guarded, inserts $h$ in the set $inits$.
    \item A $WakeUp\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``idle''. Its
        effect is to set $hist\left[ a \right]$ to a history found in
        $inits$ and to set $status\left[ a \right]$ to ``ready''.
    \item An $Accept\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``ready'', and
        updates $hist\left[ a \right]$ to $hist\left[ a \right]\star
        c$, where $c$ is a proposed command. In conservative rounds,
        the transition is additionally guarded by the condition that
        the resulting set of local acceptor histories,
        $\aset{hist'\left[ a \right] : a \in Acceptors}$, forms a chain
        in the partial order $\leq$ (this is typically implemented with a
        leader).
    \item A $Learn\left( l, h \right)$ transition, for a learner $l$
      and a history $h$, enabled when $h > learned\left[ l \right]$ and is
      smaller than the GLB of the histories of a learn quorum of acceptors. The effect of
        the transition is to set $learned\left[ l \right]$ to $h$.
    \item A $Stop\left( a \right)$ transition, for an acceptor $a$,
        enabled when $status\left[ a \right]$ is ``ready'', sets
        $status\left[ a \right]$ to ``stopped'' (note that
        $status\left[ a \right] = $ ``stopped'' prevents any further
        ``accept'' transition of acceptor $a$).
%    \item REALLY NEEDED? A $TimeOut\left( a \right)$ transition, for an acceptor $a$,
%        is enabled when $status\left[ a \right]$ is ``idle'' and sets 
%        $status\left[ a \right]$ to ``stopped'' and $hist\left[ a
%        \right]$ to the special value $None$. 
    \item An $Abort\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, is enabled when there exists a abort quorum
        $R$ such that, for every member $a$ of $R$, $status\left[ a
        \right]$ is ``stopped'' and $h \in SafeAborts\left( R
        \right)$. Its effect is to insert  $h$ in the set $aborts$. 
\end{compactitem}

On top of the additional guard on the $Accept$ transition present only
in conservative rounds, conservative and fast ACA rounds differ in
their definition of learn quorums, abort quorums, and in their
definition of the $SafeAborts\left( R \right)$ operator.
To concisely define read and learn quorums, we define 
\begin{equation}
    Q\left( f \right) = \aset{as \subseteq Acceptors :
        Card\left(as\right) \geq \left\lfloor f\times Card\left(
    Acceptors \right)\right\rfloor + 1}.
\end{equation}

In conservative ACA rounds, abort and learn quorums are defined such
that the intersection between two learn quorums is nonempty and the
intersection between a learn quorum and an abort quorum is nonempty.
The definition leads to two interesting cases: $LearnQ = AbortQ =
Q\left( 1/2 \right)$; $LearnQ = \aset{Acceptors}$ and $AbortQ =
\aset{\aset{a} : a \in Acceptors}$. The operator $SafeAborts\left( R
\right)$ is defined as the singleton set containing the maximum
element over the local histories of the acceptors in $R$ which are not
$None$. Note that the maximum exists because conservative rounds
guarantee that the histories of the acceptors form a chain.

In fast ACA rounds, abort and learn quorums are defined such that
the intersection between any two learn quorums is nonempty and the
intersection between any two learn quorums and an abort quorum is
nonempty.  The definition leads to three interesting cases: $LearnQ =
AbortQ = Q\left( 2/3 \right)$; $LearnQ = Q\left( 1/2 \right)$ and
$AbortQ = Q\left( 3/4 \right)$; $LearnQ = \aset{Acceptors}$ and
$AbortQ = \aset{\aset{a : a \in Acceptors}}$.
The operator $SafeAborts\left( R \right)$ is defined as the set of
maximal elements over the set $\aset{GLB\left( \aset{hist\left[ a
\right] : a \in R \cap L \wedge hist\left[ a \right]\neq None} \right)
: L \in LearnQ}$.

The cases in which abort quorums are singleton sets, in both
conservative and fast rounds, allow tolerating
$f$ faults with $f+1$ servers: a round can abort as long as one
acceptor is correct and a new round, possibly using new correct
servers, can take over. Note that changing round cannot happen
without the scheduling policy instructing the switchers about the
identity of the next round, and thus tolerating $f$ faults with
$f+1$ servers relies on the assumption of a reliable scheduling policy.

Define, for every learner $l$, the history variable $\overline{learned}\left[ l \right]$ which is initialized to the empty set and which is
updated each time a new local history is accepted by the learner $l$ by
inserting the new local history in $\overline{learned}\left[ l \right]$ (see \cite{AbadiLamport91ExistenceRefinementMappings} for the
definition of a history variable).
\begin{thm}
  \label{thm:rounds}
    Both conservative and fast ACA rounds implement ACA under the refinement
    mapping that consists in substituting $\overline{learned\left[ l \right]}$
    for $learned\left[ l \right]$.
\end{thm}

\section{Examples of Concrete ACA Algorithms}
\label{sec:examples}

In this section we show how to modify the rounds of Classic Paxos,
Multi-Coordinated Paxos, Chain Replication, Ring Paxos, and Fast Paxos to obtain
ACA rounds. \Cref{thm:comp} then guarantee that all those different types of
rounds can be used in the same algorithm to yield an implementation of Chain
Agreement.

\subsection{Classic Paxos}

The rounds of the Classic Paxos algorithm can be modified so as to
obtain an implementation of conservative ACA rounds.  We define
Classic Paxos ACA rounds by specializing the specification of
conservative ACA rounds, giving a concrete protocol for disseminating
the proposed commands to the acceptors and enforcing that the learned
histories form a chain.

Each Classic Paxos round has a unique leader among the acceptors which
centrally orders the proposed commands, which are accepted by the
other acceptors in the order determined by the leader.  This protocol
ensures that every local acceptor history is a prefix of the local
history of the leader, therefore guaranteeing that the local acceptor histories
form a chain.

Each acceptor broadcasts each newly accepted history to the learners, which
learn a history $h$ when they receive enough extensions of $h$ from the
acceptors.  When instructed by the scheduling policy to abort, a
switcher sends a stop message to the acceptors, which irrevocably stop
updating their local history and send back to the switcher an
acknowledgement containing their local history. A switcher
determines an abort history once it has received acknowledgments from
an abort quorum of acceptors $R$, using the operator $SafeAborts\left(
R \right)$.

The specification of Classic Paxos ACA rounds uses the variables of
the specification of conservative ACA rounds, namely the variables
$proposed$, $inits$, $aborts$, the arrays $learned\left[ l \right]$,
$status\left[ a \right]$, and $hist\left[ a \right]$, and two
additional arrays $accepted\left[ l \right]\left[ a \right]$ and
$stop\left[ s \right]\left[ a \right]$, where $l$ is a learner, $a$ is
an acceptor, and $s$ is a switcher.

There is also a network component that we do not describe explicitly.
However, the network allows any servers to communicate by sending and
receiving messages.

Initially, the variables $proposed$, $inits$, $aborts$, and, for every
learner $l$, $learned\left[ l \right]$ are empty sets. For every
acceptor $a$, $status\left[ a \right]$ is ``idle'' and $hist\left[ a
\right]$ is the special value $None$. For every learner $l$ and acceptor $a$,
$accepted\left[ l \right]\left[ a \right]$ is the special value
$None$. For every switcher $s$ and acceptor $a$, $stopped\left[ s
\right]\left[ a \right]$ is set to $false$.  There are initially no
messages in the network.

The next-state relation is composed of the following types of
transitions, where the definitions of learn quorums, abort quorums,
and of the $SafeAborts\left( R \right)$ operator are the ones of conservative
ACA rounds.
\begin{compactitem}
    \item A $Propose\left( p,c \right)$ transition, for a proposer $p$
        and a command $c$, not guarded, inserts $c$ in the set
        $proposed$ and sends the message $\aseq{\quo{prop},c}$ to
        the leader.
    \item An $Init\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, not guarded, inserts $h$ in the set $inits$ and
        sends the message $\aseq{\quo{init},h}$ to the leader.
    \item A $WakeUp\left( leader \right)$ transition, enabled when
        $status\left[ leader \right]$ is ``idle'' and the leader can
        receive a $\aseq{\quo{init},h}$ message. Its effect is to
        receive the message, set $hist\left[ leader \right]$ to $h$,
        to set $status\left[ leader \right]$ to ``ready'', and to
        broadcast the message $\aseq{\quo{leader-accept},h}$ to all
        other acceptors.
    \item An $Accept\left( leader \right)$ transition, enabled when
        $status\left[ leader \right]$ is ``ready'' and the leader can
        receive a $\aseq{\quo{prop},c}$ message. The effect of the
        action is to receive the message, to update $hist\left[ leader
        \right]$ to $hist\left[ leader \right]\star c$, and to
        broadcast the message $\aseq{\quo{ack},hist\left[ leader
        \right]\star c}$ to the learners, and to broadcast the message
        $\aseq{\quo{leader-accept},hist\left[ leader \right]\star c}$
        to all the other acceptors.
    \item An $Accept\left( a \right)$ transition, for an acceptor $a$
        which is not the leader, is enabled when $status\left[ a
        \right]$ is ``ready'' and $a$ can receive a
        $\aseq{\quo{leader-accept},h}$ message where $h > hist\left[ a
        \right]$. The effect of the action is to receive the message,
        to update $hist\left[ a \right]$ to $h$, and to broadcast the
        message $\aseq{\quo{ack},hist\left[ a \right]\star c}$ to the
        learners.
    \item A $RcvAck\left( l \right)$ transition, for a learner $l$, is
        enabled when $l$ can receive a message $\aseq{\quo{ack},h}$
        from an acceptor $a$. Its effect is to receive the message and
        to set $accepted\left[ l \right]\left[ a \right]$ to $h$.
    \item A $Learn\left( l, h \right)$ transition, for a learner $l$
        and a history $h$, is enabled when $h > Max\left(
        learned\left[ l \right] \right)$ and there is a learn quorum
        $Q$ of acceptors such that $h = GLB\left( \aset{accepted\left[
        l \right]\left[ a \right] : a \in Q }\right)$. Its effect is
        to insert $h$ in $learned\left[ l \right]$.
    \item A $Stop\left( s \right)$ transition, for a switcher $s$,
        always enabled, broadcasts a $\aseq{\quo{stop}}$ message to all
        the acceptors.  This transition models a switcher being
        instructed by the scheduling policy to abort the current round.
    \item A $Stop\left( a \right)$ transition, for an acceptor $a$,
        enabled when $a$ can receive a $\aseq{\quo{stop}}$ message
        from a switcher $s$. Its effect is to receive the message, set
        $status\left[ a \right]$ to ``stopped'', and to send the
        message $\aseq{\quo{stopped},hist\left[ a \right]}$ to the
        switcher $s$.
    \item A $RcvStopped\left( s \right)$ transition, for a switcher
        $s$, enabled when $s$ can receive a $\aseq{\quo{stopped},h}$
        message from an acceptor $a$. Its effect is to receive the
        message and to set $stopped\left[ s \right]\left[ a \right]$
        to $h$.
    \item An $Abort\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, is enabled when there exists an abort quorum
        $R$ such that, for every member $a$ of $R$, $stopped\left[ s
        \right]\left[ a \right]$ is not $false$ and $h \in
        SafeAborts\left( R \right)$, where $SafeAborts\left( R
        \right)$ is computed using the array $stopped\left[ a
        \right]$. Its effect is to insert  $h$ in the set $aborts$. 
\end{compactitem}
Compared to the rounds of the original Classic Paxos, Classic Paxos ACA
rounds add an extra level of indirection when changing round: in the
original rounds, the leader of the new round directly queries the
acceptors of the preceeding rounds, whereas in ACA rounds, the
switchers query the acceptors and then send their abort histories to
the leader. However, changing round is an infrequent event, therefore
this difference should not have much practical impact on performance.
\begin{thm}
  Classic Paxos ACA rounds satisfy Abortable Chain Agreement.
\end{thm}
\begin{proof}
  A Classic Paxos ACA round implements the specification of Abortable
  Chain Agreement under the refinement mapping consisting in
  projecting the state of the round onto the variables $proposed$,
  $inits$, $aborts$, and, for every learner $l$, $learned\left[ l
  \right]$.
\end{proof}

\subsection{Multi-Coordinated Paxos, Chain Replication, and Ring Paxos.}

Multi-Coordinated Paxos, Chain Replication, and Ring Paxos rounds have a similar
structure as Classic Paxos rounds but differ in the way the leader is
implemented and in the way that the histories of the leader are disseminated to
the other acceptors.

Multi-Coordinated Paxos avoids depending on a unique leader by using a
distributed leader implementation that can make progress as long as a
strict majority of the acceptors are correct, trading off resilience
for a higher time complexity. Conservative ACA
rounds can be implemented like with Classic Paxos, replacing the
leader by the distributed leader of Multi-Coordinated Paxos.

In Chain Replication, acceptors are arranged in a chain whose head is
the leader of the round. As in Classic Paxos, abort histories and
proposed commands are sent to the leader. However, instead of the
leader directly sending its local history to all the other acceptors,
the local history of the leader is
forwarded along the chain from one acceptor to the other until it
reaches the last acceptor, which sends the history to the learners. 
By spreading the load more evenly on the all the servers, Chain Replication
can achieve higher throughput that Classic Paxos.
Conservative ACA rounds can be implemented like with Classic Paxos,
replacing the broadcast of the leader by the propagation of the leader's history
along the chain of servers.

Ring Paxos optimizes Chain Replication by having the leader broadcast
commands to the acceptors using IP multicast and only sending hashes
of the commands along the chain. Ring Paxos round can be modified to implement
conservative ACA rounds in a similar way as for Chain Replication.

\subsection{Fast Paxos}

Fast Paxos is composed of two types of rounds: classic rounds, like in Classic
Paxos, and fast rounds.
The fast rounds can be transformed into
implementations of fast ACA rounds. Instead of sending their
commands to a leader, as in Classic Paxos, the proposers of fast
rounds directly broadcast their commands to all the acceptors. As long
as commands are received in the same order by a learn quorum of
acceptors or are received in different orders but commute, commands can be learned in two message-propagation delays instead of three in Classic Paxos.
However, if non-commuting commands are received in different orders by
several acceptors, the local history of the acceptors may not form a
chain anymore and the rounds must abort. The fast rounds of Fast
Paxos implement fast ACA rounds.

Fast Paxos ACA rounds are specified using the same set of variables as for
Classic Paxos, initialized to the same values.
The next-state relation is composed of the following types of
transitions, where the definitions of learn quorums, abort quorums,
and of the $SafeAborts\left( R \right)$ operator are the ones of fast
ACA rounds.
\begin{compactitem}
    \item A $Propose\left( p,c \right)$ transition, for a proposer $p$
        and a command $c$, not guarded, inserts $c$ in the set
        $proposed$ and broadcasts the message $\aseq{\quo{prop},c}$ to
        all the acceptors.
    \item An $Init\left( s, h \right)$ transition, for a switcher $s$
        and a history $h$, not guarded, inserts $h$ in the set $inits$ and
        broadcasts the message $\aseq{\quo{init},h}$ to all the acceptors.
    \item A $WakeUp\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``idle'' and $a$
        can receive an $\aseq{\quo{init},h}$ message. Its effect is to
        receive the message, set $hist\left[ a \right]$ to $h$, and to
        set $status\left[ a \right]$ to ``ready''.
    \item An $Accept\left( a \right)$ transition, for an acceptor $a$,
        is enabled when $status\left[ a \right]$ is ``ready'' and $a$
        can receive a $\aseq{\quo{prop},c}$ message. The effect of the
        action is to receive the message, to update $hist\left[ a
        \right]$ to $hist\left[ a \right]\star c$, and to broadcast
        the message $\aseq{\quo{ack},hist\left[ a \right]\star c}$ to
        the learners.
    \item The $RcvAck\left( l \right)$ transitions, for a learner $l$,
        the $Learn\left( l, h \right)$ transitions, for a learner $l$
        and a history $h$, the $Stop\left( s \right)$ transitions, for
        a switcher $s$, $Stop\left( a \right)$ transitions, for an
        acceptor $a$, the $RcvStopped\left( s \right)$ transitions,
        for a switcher $s$, and the $Abort\left( s, h \right)$
        transitions, for a switcher $s$ and a history $h$, which are
        all the same as in Classic Paxos ACA rounds.
\end{compactitem}

As for Classic Paxos ACA rounds, Fast Paxos ACA rounds implement ACA
under the refinement mapping consisting projecting the state of the
round onto the variables $proposed$, $inits$, $aborts$, and, for every
learner $l$, $learned\left[ l \right]$.


\newpage

\printbibliography


\begin{appendix}
  
  \label{sec:isaproofs}
 
%  \includepdf[pages={1},pagecommand={\section{Mechanical Proof of the
%  Composition Theorem in Isabelle/HOL}\label{sec:isaproofs}},scale=1]{../IsabellePDFS/podctheories.pdf}
%  \includepdf[pages={2-},pagecommand={},scale=1]{../IsabellePDFS/podctheories.pdf}
  
\end{appendix}

\end{document}
